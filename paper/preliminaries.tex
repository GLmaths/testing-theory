%%% THIS TEXT IS FROM THE ESOP2025 PAPER


\input{axioms-figure}




%The \outputfeedback axiom states that any message emitted by an agent
%is immediately available as input to the agent itself.

%% These axioms are typically enjoyed by LTS of calculi in which
%% communication takes place via a global unordered mailbox.
%% In turn, this communication model is the one that a priori allows for the most
%% \nondeterminismT, and this is why we favour it.


%% gb{The~$\tau$ action denotes internal computation of an agent, or a
%%   interactions between two agents. For instance, the computations
%%   in the system~$\csys{ \server_0 }{ \client_0 }$, where~$\server_0$
%%   and~$\client_0$ are give in \rfig{first-example} amount to
%%   $\csys{ \server_0 }{ \client_0 } \st{\tau}
%%   \csys{ \server_1 }{ \client_2 } \st{\tau} \csys{ \server_3 }{
%%   \client_3 }$.
%%   Note that \outputcommutativity implies a lack of causality between
%%   the client output $\co{{\tt str}}$ and its input ${\tt int}$, and hence
%%   the order of interactions depends on the order of the inputs in the
%%   server side.}
%%% NOT IMPORTANT ON A FIRST READ
%% We find it worth attention for it is the one that allows for the most
%% \nondeterminismT, and thus proofs that tackle this model can be adapted to more
%% deterministic settings, for instance when asynchrony is implemented
%% via ordered queues, as in \cite{josephs}.
%% The more deterministic the semantics, the easier the reasoning,
%% as already shown by theories of \mustpreorder in \CCS as compared
%% to the ones for session types \cite{DBLP:journals/mscs/BernardiH16}.
%% In output-buffered agents, outputs enjoy the \outputcommutativity\ and

%% \outputfeedback\ axioms.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\outputcommutativity  &  \outputfeedback & \outputconfluence

\begin{figure}[t]
  \hrulefill
  %     (* further details omitted for readability. *)
  \begin{minted}{coq}
    Class Sts (A: Type) := MkSts {
      sts_step: A → A → Prop;
      sts_stable: A → Prop; }.

    Inductive ExtAct (A: Type) :=     Inductive Act (A: Type) :=
    | ActIn (a: A) | ActOut (a: A).   | ActExt (ext: ExtAct A) | τ.

    Class Label (L: Type) :=          Class Lts (A L : Type) `{Label L} := 
    MkLabel {                         MkLts {
     label_eqdec: EqDecision L;        lts_step: A → Act L → A → Prop;
     label_countable: Countable L; }.  lts_outputs: A → finite_set L;
                                       lts_performs: A → (Act L) → Prop; }.
  \end{minted}
    %  lts_state_eqdec: EqDecision A;
  %       lts_stable_decidable: ∀ x ℓ, Decision (lts_stable x ℓ);
  %       lts_step_decidable: ∀ a l b, Decision (lts_step a l b);
  %      lts_outputs_spec1 s1 x s2 : lts_step s1 (ActExt (ActOut x)) s2 → x ∈ lts_outputs s1;
%      lts_outputs_spec2 s1 x : x ∈ lts_outputs s1 → ∃ s2, lts_step s1 (ActExt (ActOut x)) s2;
%      lts_stable_spec1: ∀ x ℓ, ¬ lts_stable x ℓ → { y | lts_step x ℓ y };
%      lts_stable_spec2: ∀ x ℓ, { y | lts_step x ℓ y } → ¬ lts_stable x ℓ;
  \caption{Highlights of our Sts and Lts typeclasses.}
  \label{fig:mechanisation-lts}
  \label{fig:sketch-mechanisation-sts}
  \hrulefill
\end{figure}



%%%% Section START %%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}
\label{sec:preliminaries}
%As hinted in the Introduction,
We model individual programs such as
servers~$\server$ and clients~$\client$ %are modelled
as LTSs obeying Selinger axioms, while client-server systems
$\csys{\server}{\client}$ are modelled as state transition systems
with a reduction semantics. We now formally define this two-level
semantics.
%for programs and systems.

% \ilacom{TODO: Introduce first the sets of names $\Names$ and conames
%   $\overline{\Names}$, representing process inputs and outputs
%   respectively. Then introduce the silent or invisible action $\tau$,
%   and define the set of process actions to be
%   $\Acttau \;\;\eqdef\;\; \Names \uplus \{ \co a \mid a \in \Names \}
%   \uplus \{ \tau \} $. This is the set of actions of CCS and of
%   Selinger LTSs. Then insert the paragraph \emph{Labelled transition
%     systems}, and say that here we assume $L$ to be $\Acttau$.  Now
%   add a paragraph \emph{Client-server systems}, and explain that the
%   STS semantics of systems is derived from the LTS semantics of
%   programs as specified by the rules in Figure~\ref{fig:rules-STS}.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Labelled transition systems}
A \emph{labelled transition system} (LTS) is a triple
$\genlts = \lts{ \States }{ L }{ \st{} }$ where~$\States$ is the set
of states, $L$~is the set of labels
% defined as $
%   L \;\;\eqdef\;\; \Names \cup \{ \co a \mid a \in \Names \} \cup \{ \tau \}
%   $
  and ${\st{}}
  \subseteq \States \times L \times \States$ is the transition
  relation.
  When modelling programs as LTSs, we use transition labels to
  represent program actions. The set of labels in Selinger LTSs has
  the same structure as the set of actions in Milner's calculus \CCS:
  one assumes a set of names~$\Names$, denoting input actions and
  ranged over by~$\aa, \ab, c$, a complementary set of
  conames~$\overline{\Names}$, denoting output actions and ranged over
  by $\co{\aa}, \co{\ab}, \co{c}$, and an \emph{invisible}
  action~$\tau$, representing internal computation.
The set of all actions, ranged over by $\alpha, \beta, \gamma$,
is given by
$\Acttau \;\;\eqdef\;\; \Names \uplus \overline{\Names}
%\{ \co a \mid a \in \Names \}
   \uplus \{ \tau \} $.
We use $\mu, \mu'$ to range over the set of visible actions $\Names
\uplus \overline{\Names}$, and we extend the complementation function
$\co\cdot$ to this set by letting ${\co{\co \aa}} \eqdef \aa$.
In the following, we will always assume $L = \Acttau$.
Once the LTS is fixed, we write %use the infix notation
$\state \st{\alpha} \stateA$ to mean that
$(\state,\alpha,\stateA)~\in~{\st{}}$ and $ \state \st{ \alpha }$
to mean $\exists \stateA \suchthat \state \st{\alpha} \stateA$.
%
% In the sequel, we shall loosely use the terms ``input'' and ``output''
% either for an input/output action or for an input/output transition.
% %(i.e., a transition labelled by an input/output action).
% \ilacom{Take off this sentence?}

% {\em Notation:}
We use $\genlts$ to range over LTSs. To reason
simultaneously on different LTSs, we will use the
symbols~$\genlts_A$ and~$\genlts_B$ to denote respectively
the LTSs~$\lts{\StatesA}{L}{\st{}_A}$ and~$\lts{\StatesB}{L}{\st{}_B}$.


In our mechanisation LTSs are borne out by the typeclass
\mintinline{coq}{Lts} in \rfig{mechanisation-lts}. The states of the LTS
have type $\States$, labels have type $L$, and \mintinline{coq}{lts_step} is
the characteristic function of the transition relation, which we
assume to be decidable.  We let $O(\state) = \outactions{ \state }$
and $I(\state) = \inactions{ \state}$ be respectively the set of
outputs and the set of inputs of state~$\state$.  % (\coqSyn{outputs_of}, \coqSyn{inputs_of}).
We assume that the set $O(\state)$
% assume that the set of output actions of any state of~$\StatesA$
% is given by the function \mintinline{coq}{lts_outputs} and
  is finite for any $\state$.
  % , \ie $\forall p \in \States . |O(p)| \in \N$.
  In our mechanisation, the set
$O(\state)$ is rendered by the function \mintinline{coq}{lts_outputs},
and we shall also use a function \mintinline{coq}{lts_performs} that
% We also assume that the function \mintinline{coq}{lts_performs}
lets us decide whether a state can
perform a transition labelled by a given action.


%%%%% ILARIA: moved this at the end of previous paragraph
%
% {\em Notation:} we use $\genlts$ to range over LTSs. To reason
% simultaneously on different LTSs, we will use the
% symbols~$\genlts_A$ and~$\genlts_B$ to denote respectively
% some LTS~$\lts{\StatesA}{L}{\st{}_A}$ and some LTS~$\lts{\StatesB}{L}{\st{}_B}$.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \ilacom{DO we still need the following?}
% Parallel composition is defined over
% LTSs with the same labels $\lts{\States_1}{L}{\st{}_1}$ and
% $\lts{\States_2}{L}{\st{}_2}$, and describes the transition relation
% of the LTS $\lts{\States_1 \times \States_2}{L}{\st{}}$, where the
% transition relation $\st{}$ is defined in the standard way
% in~\rfig{}.
% This is also the semantics of \svrclt systems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%% ILARIA (14/12/23): Rules adapted from those of ACCS in Appendix


\begin{figure}[t]
\hrulefill
$$
\begin{array}{lll}
  \stauserver
  &
  \stauclient
  &
  \scom\\
\begin{prooftree}
{ \server \st{\tau} \server' }
  \justifies
      {\csys{\server}{\client} \st{} \csys{\server'}{\client}}
\end{prooftree}
  \hspace{3em}
&
\begin{prooftree}
  \client \st{\tau} \client'
  \justifies
      {\csys{\server}{\client} \st{} \csys{\server}{\client'}}
\end{prooftree}
  \hspace{3em}
&
\begin{prooftree}
  \server\st{ \mu } \server' \quad \client \st{\co{ \mu }} \client'
  \justifies
  \csys{\server}{\client} \st{} \csys{\server'}{\client'}
\end{prooftree}
\end{array}
$$
\caption{The STS of server-client systems.}
% The metavariables are
% $\aa \in \Names, \co{\aa} \in \overline{\Names}, \mu \in \Act, \and
% \alpha \in \Acttau$.
  \label{fig:rules-STS}
\hrulefill
\end{figure}


\paragraph{Client-server systems} %
%
%%%%%% ILARIA: shortened for CONCUR
%
% We denote with $\csys{\server}{\client}$ a pair of states
% in which~$\server$ is deemed the server of client~$\client$.
% We call the pair $\csys{\server}{\client}$ a {\em \svrclt} system,
% for short a {\em system}. 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%
%
A {\em \svrclt} system (or {\em system}, for short) is a pair
$\csys{\server}{\client}$ in which~$\server$ is deemed to be the server of
client~$\client$.
%
 %  and we assume a reduction semantics for~$- \llceil -$. For example,
%   if $\server$ and
%   $\client$ are terms of a language endowed with the parallel
%   composition~$ -\Par - $, then the semantics of~$- \llceil -$ is the
%   same one of~$ - \Par -$, but with the server and the client being
% distinguished, in order to prevent $\goodSym$ terms to ``commute'' from
% the server process into the client process.
%% \footnote{
%% In the implementation the reduction semantics is adapted in the
%% obvious way, %(\coqMT{lts_sys_s}).
%% and we use a location \texttt{c} for the client a location \texttt{s}
%% for the server, and systems are coded as \lstinline!s[p] || c[r]!.
%% These locations prevent server code from migrating into the client side,
%% and vice-versa.
%% }
%%%%%%%%%%%%%%%%%%%%%%%%%%
%
In general, every system~$\csys{\server~}{~\client}$ is the root of a
{\em state transition system} (STS), $\sts{ \SysStates }{ \st{ }} $,
where~$\SysStates$ is the set of states and~$\st{}$ is the reduction
relation.  For the sake of simplicity\footnote{In general the
  reduction semantics and the LTS of a calculus are defined
  independently, and connected via the Harmony lemma
  (\cite{sangiorgi}, Lemma 1.4.15 page 51).  %While this is out of
  %scope,
  We have a mechanised proof of it.}%
  %the equivalence~$\simeq$ used in our typeclass
  %\lstinline!LtsEq! enjoys the main property behind the proof of the
%Harmony lemma.}
  we derive the reduction relation from the LTS
semantics of servers and clients as specified by the rules in
\rfig{rules-STS}.
  %\ila{which is derived from the LTS
%  semantics of servers and clients as specified by the rules in
  %  Figure~\ref{fig:rules-STS}.}
In our mechanisation (\rfig{sketch-mechanisation-sts}), \mintinline{coq}{sts_step}
% \lstinline!sts_step!
is the
characteristic function of the reduction relation~$\st{}$, and
% \lstinline!sts_stable!
\mintinline{coq}{sts_stable}
is the function that states whether a state can
reduce or not. Both functions are assumed decidable.
% \ilacom{The font of \lstinline!sts_step! and \lstinline!sts_stable! is
%   different from that of \mintinline{coq}{lts_step}. Is that intended?}
% %
%\ilacom{I would put a definition environment for the following
%  definition, as for Definition~\ref{def:inf-transition-sequence}}\\

% \noindent
% \ilacom{I have simplified the following definition, as suggested by
%  CONCUR Reviewer B, but I've left the definition
%  environment for visibility.}

\begin{definition}[Computation]
  Given an STS $\sts{ \SysStates }{ \st{} }$ and a state
  $\sysstate_0 \in \SysStates$, a %\emph{reduction sequence} or
  \emph{computation} of $\sysstate_0$ is a finite or infinite
  reduction sequence starting from $\sysstate_0$.
  A computation is
{\em maximal} if either it cannot be extended or it is infinite.
  \hfill$\blacksquare$
  \end{definition}

% \begin{definition}[Computation]
%   Given an STS $\sts{ \SysStates }{ \st{} }$ and a state
%   $\sysstate_0 \in \SysStates$, a %\emph{reduction sequence} or
%   \emph{computation} of $\sysstate_0$ is a finite or infinite
%   reduction sequence\footnote{Which is defined as a coinductive type
%     in our Coq development.}, \ie a partial function $\eta$ from $\N$
%   to $\SysStates$ whose domain is downward-closed, such that
%   $\sysstate_0 = \eta(0)$ and for each
%   $n \in \dom\eta \setminus \{0\}$,
%   $\eta(n-1) \st{ } \eta(n)$.\hfill$\blacksquare$
% \end{definition}

% A computation~$\eta$ is
% {\em infinite} if $ \mathit{dom}(\eta) = \N$.
% A computation~$\eta$ is
% {\em maximal} if either it is infinite or it cannot be extended,
% \ie $\eta(n_{max}) \Nst{}$ where $n_{max} = max(
% \mathit{dom}(\eta))$.



To formally define the \mustpreorder, we assume a decidable
predicate~$\goodSym$ over clients.  A
computation~$ \csys{\server~}{~\client} = \csys{ \server_0 }{
  \client_0 } \st{ } \csys{ \server_1 }{ \client_1 } \st{ } \csys{
  \server_2 }{ \client_2 } \st{ } \ldots $ is {\em successful} if
there exists a state $\csys{ \server_i}{ \client_i}$ such that
$\good{\client_i}$.
%
% A computation~$\eta$ of $\sysstate_0 =
% \csys{\server_0}{\client_0}$
% is {\em successful} if there exists $ n \in \N $ such that
% $\good{ \mathsf{snd}(\eta(n)) }$. 
We assume the predicate $\goodSym$
to be \emph{invariant under outputs}:
%
\begin{equation}
\label{eq:good-invariance}
  \text{If} ~~\client \st{ \co{a}} \client' ~~ \text{then}~~
  \good{ \client} \iff \good{ \client'}
\end{equation}
%
All the previous works on
asynchronous calculi implicitly make this
assumption, since they rely on ad-hoc actions such as $\omega$ or
$\checkmark$ to signal success and they treat them as outputs.
In \rapp{accs} we show that this
assumption holds for the language~\ACCS~(the asynchronous variant of
\CCS) extended with the
process~$\Unit$.
%This is consistent with the \outputcommutativity axiom.
%
Moreover, when considering an equivalence on programs $\simeq$ that is
compatible with transitions, in the sense of Figure~\ref{fig:Axiom-LtsEq}, we
assume the predicate $\goodSym$ to be preserved also by this equivalence.
%
These assumptions are met by the frameworks in
  \cite{DBLP:conf/fsttcs/CastellaniH98,DBLP:journals/iandc/BorealeNP02,DBLP:journals/jlp/Hennessy05}.
  % but let us abstract away from details,
  %%%% NEW
  %%% \gb{Here we opt for a more general treatment based on LTSs, and use calculi only to streamline examples.}
  %%%%% OLD
  %
  %%% ILARIA: took off the following for CONCUR
  %
  % Here we abstract away from the calculi used in those papers, and we opt
  % for a more general treatment based on LTSs.
  %
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% \begin{definition}[\coqTS{iexec_from}]
%%   \label{def:inf-transition-sequence}
%%   Given a state $\state_0 \in \Proc$, %we say that
%%   an {\em infinite transition sequence} of $\state_0$ is a {\em total}
%%   function $ \eta : \N \longrightarrow \Proc \times \Acttau$ such that
%%    for every
%%     $n \in N \wehavethat \eta(n) = (\state_n,\alpha_n)$ and $\state_n \stx{\alpha_n} \state_{n+1}$.
%%    If a finite trace $\trace$ or an infinite transition sequence $\eta$
%%    contain only $\tau$ actions, it is called a {\em computation}.~\hfill$\blacksquare$
%% \end{definition}




%We follow \cite{DBLP:conf/lics/BredeH21} and define infinite sequences
%of processes as functions $\N \longrightarrow \Proc$.
%A {\em computation} $\eta$ is a sequence of processes $\seq{p_0,p_1,\ldots}$
%such that for every $n \in \N \wehavethat p_n \st{\tau} p_{n+1}$.
%We range over computations with $\eta$.

%% \ilacom{In the next couple of sentences, you use $\eta_{n}$ instead of
%%   $\eta(n)$.  I'm not sure it's a good idea, because one might want to
%%   use $\eta_1$ and $\eta_2$ to denote two different computations from
%%   a given state $\state_0$.}\\





%% , and for system use a parallel
%% operation $\Par$ that distinguishes the identities of the client and
%% the server, so that a $\Unit$ in a server~$\server$ does not mean that
%% the state $\csys{ \server }{ \client }$ is succesful.

\begin{definition}[Client satisfaction]%\coqME{must_ext}
  \label{def:must-extensional}
  We write $\Must{\server}{\client} $ if every maximal
  computation of $\csys{\server}{\client}$ is successful.\hfill$\blacksquare$
\end{definition}

%%% NO LONGER USEFUL
%% \noindent
%% We write $\NMust{\server}{\client}$ to mean $\lnot
%% (\Must{\server}{\client}) $. The prefix notation for $\opMust$ is unusual,
%% and we adopt it for it simplifies the presentation of our results, in
%% particular the statement of \req{musti-preserved-by-nf}.


\begin{definition}[\mustpreorder]% \coqMT{ctx_srv}, ]
  \label{def:testleq}
  \label{def:testleqS}
We let $ \server \testleqS \serverB$ whenever for every
client $r$ we have that
$\Must{\server}{\client}$ implies $\Must{\serverB}{\client}$.\hfill$\blacksquare$
\end{definition}

%% \noindent
%% \gb{The predicate $\opMust$ is a
%%   natural way to model liveness properties, and~$\testleqS$ is the
%% obvious contextual equivalence to preserve such properties, while
%% allowing code refactoring that is not observable by clients.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 

\begin{example}
\label{ex:max-comp}
 Consider the system~$\csys{ \server_0 }{ \client_0 }$, where~$\server_0$
  and~$\client_0$ are the server and client given in
  \rfig{first-example}. The unique maximal computation of this system is
  $\csys{ \server_0 }{ \client_0 } \st{} \csys{ \server_1 }{ \client_1
  } \st{} \csys{ \server_3 }{ \client_3 }$.
This computation is successful since it leads the client to the $\goodSym$ state
$\client_3$.
% which is  $\goodSym$.
Hence, client  $\client_0$ is
satisfied by server $\server_0$.
%
%Note that,
Since \outputcommutativity implies a lack of causality
between the output $\co{{\tt str}}$ and the input ${\tt int}$ in the
client, it is the order between the input ${\tt str}$ and the output
$\co{\tt int}$ in the server that guides the order of client-server
interactions.\hfill$\qed$
\end{example}




\paragraph{A closer look at Selinger axioms}
Let us now discuss the axioms in \rfig{axioms}.
%Let us now discuss the axioms in Figure~\ref{fig:axioms}.
%As mentioned already,
The \outputcommutativity axiom expresses the non-blocking behaviour of
outputs: %it says that
an output cannot be a cause of any subsequent transition, since it can
also be executed after it, leading to the same resulting state. Hence,
outputs are concurrent with any subsequent transition.  The
\outputfeedback axiom says that an output followed by a complementary
input can also synchronise with it to produce a $\tau$-transition.
% (since the output and the input are in fact concurrent).
These first
two axioms specify properties of outputs that are followed by another
transition. Instead, the following three axioms, \outputconfluence,
\outputdeterminacy and \outputtau, specify properties of outputs that
are co-initial with another transition\footnote{Two transitions are
  co-initial if they stem from the same state.}. The
\outputdeterminacy and \outputtau axioms apply to the case where the
co-initial transition is an identical output or a $\tau$-transition
respectively, while the \outputconfluence axiom applies to the other
cases.  When taken in conjunction, these three axioms state that outputs
cannot be in conflict %(i.e., mutually exclusive)
with any co-initial transition, except when this is a
$\tau$-transition: in this case, the \outputtau axiom allows for a
confluent nondeterminism between the $\tau$-transition on one side and
the output followed by the complementary input on the other side.
% since the $\tau$-transition may represent a synchronisation between the
% output and the input.

% Since the axiom \outputdeterminacyinv is not part of Selinger
% axioms, we discuss it in the next paragraph.



We now explain the novel \outputdeterminacyinv axiom.  It is the dual of \outputdeterminacy, as it states that also backward transitions with identical outputs lead to the same state. The intuition is that if two programs arrive at the same state by removing the same message from the mailbox, then they must coincide. % This seems natural if communication takes place
% via a shared mailbox.
This axiom need not be assumed in \cite{DBLP:conf/concur/Selinger97} because it can be derived from Selinger axioms when modelling a calculus like~\ACCS equipped with a parallel composition operator~$\parallel$ (see Lemma~\ref{lem:output-shape} in Appendix~\ref{sec:accs}).  We use the \outputdeterminacyinv axiom only to prove a technical property of clients (\rlem{inversion-gen-mu}) that is used to prove our completeness result.



\paragraph{Calculi}
%% Given a calculus of interest, together with the inference rules to
%% which give its LTS, one would like to show that said LTS satisfies the
%% axioms in \rfig{axioms}. For example,
%% \cite{DBLP:conf/concur/Selinger97} does so for the LTS of asynchronous \ACCS modulo bisimulation.
A number of asynchronous calculi
\cite{DBLP:conf/ecoop/HondaT91,boudol:inria-00076939,DBLP:conf/fsttcs/CastellaniH98,DBLP:journals/toplas/HennessyR02,palamidessi_2003,DBLP:conf/birthday/Sangiorgi19}
have an LTS that enjoys the axioms in \rfig{axioms}, at least up to
some structural equivalence~$\equiv$. The reason is that these calculi
syntactically enforce outputs to have no continuation, \ie outputs can
only be composed in parallel with other
processes.\footnote{In the calculus \TACCS~(a variant of \ACCS
    tailored for testing semantics)
    of~\cite{DBLP:conf/fsttcs/CastellaniH98} there is a construct of
    asynchronous output prefix, but its behaviour is to spawn the
    corresponding atom in parallel with the continuation, so it
      does not act as a prefix.}.  For
example, Selinger~\cite{DBLP:conf/concur/Selinger97} shows that the
  axioms of \rfig{axioms} hold for the LTS of the calculus~\ACCS (the
asynchronous variant of CCS\footnote{The syntax of~\ACCS, which
    is closely inspired by that of the asynchronous $\pi$-calculus
    with input- and $\tau$-guarded choice~\cite{ACS96,ACS98}, is given
    in~\req{syntax-processes} and discussed later.})  modulo
bisimulation, and in \rapp{accs}
(\rlem{ACCSmodulos-equiv-is-out-buffered-with-feedback})
%we prove this
we prove that they hold also for the LTS {of \ACCS modulo $\equiv$:%\lts{\modulo{\ACCS}{\equiv}}{L}{\modulo{\st{}}{\equiv}}:
\begin{lemma}
  \label{lem:ACCS-obaFB}
  We have that $\lts{\modulo{\ACCS}{\equiv}}{L}{\modulo{\st{}}{\equiv}} \in \obaFB$.
\end{lemma}
}
%%% GB:CLAIM olé olé TO BE HIDDEN. REQUIRES MUCH MORE WORK. 
%% We claim that also the early style LTS of the asynchronous
%% $\pi$-calculus enjoys the axioms of \rfig{axioms}.
To streamline
reasoning modulo some (structural) equivalence we introduce the
typeclass \mintinline{coq}{LstEq}, % to the hierarchy of
% typeclasses.
whose instances are LTSs
% in which an equivalence~$\simeq$ exists,
equipped with an equivalence~$\simeq$
that satisfies the property in \rfig{Axiom-LtsEq}.
% \footnote{For
% instance, to reason on the LTS of \ACCS terms modulo the
% standard structural equivalence~$\equiv$, in our mechanisation it
% suffices to use the LTS \lts{\ACCS}{L}{\st{}\cdot\equiv}. \leo{I don't
%   get it} \ilacom{I don't understand it either.  I would omit this
%   footnote altogether.}}
Defining output-buffered agents with feedback using \mintinline{coq}{LtsEq}
does not entail any loss of generality, because the equivalence~$\simeq$
can be instantiated using the identity over the states~$\States$.
Further details can be found in \rapp{structural-congruence}.




%% \begin{figure}[t]
%% \hrulefill
%% $$
%% \begin{array}{lcl}
%%   p,q,r             & ::= &
%% \out{a}
%% \BNFsep g
%% \BNFsep p \Par p
%%  \BNFsep \rec{p}
%%  \BNFsep x
%% \\[.5em]
%%  g             & ::= &
%%  \Nil
%%  \BNFsep a.p
%%  \BNFsep \tau.p
%%  \BNFsep g \extc g
%% \end{array}
%% $$
%% \vspace{-1em}
%% \caption{Syntax of (core)~\ACCS.}% (\protect{\coqSyn{proc}}).
%% %where $\mu \in \Names, \mu_{\tau} \in \Names_{\tau}$.
%% %\caption{A minimal syntax for processes.% (\protect{\coqSyn{proc}}).
%% \hrulefill
%% \label{fig:syntax-processes}
%% \end{figure}



When convenient we denote LTSs using the following minimal syntax for \ACCS:
%which we give in \rfig{syntax-processes},
\begin{equation}
  \label{eq:syntax-processes}
    p,q,r ::= 
\out{\aa}
\BNFsep g
\BNFsep p \Par p
 \BNFsep \rec{p}
 \BNFsep x,
\qquad
 g ::= 
 \Nil
 \BNFsep a.p
 \BNFsep \tau.p
 \BNFsep g \extc g
%% \begin{array}{l@{\hskip 2pt}c@{\hskip 2pt}l@{\hskip 20pt}l@{\hskip 2pt}c@{\hskip 2pt}l}
%%   p,q,r & ::= &
%% \out{\aa}
%% \BNFsep g
%% \BNFsep p \Par p
%%  \BNFsep \rec{p}
%%  \BNFsep x,
%% &
%%  g & ::= &
%%  \Nil
%%  \BNFsep a.p
%%  \BNFsep \tau.p
%%  \BNFsep g \extc g
%% \end{array}
\end{equation}

as well as its standard LTS\footnote{Where the recursion rule is replaced by the one
    usually adopted for testing semantics, which introduces a
    $\tau$-transition before each unfolding.}  whose properties we
discuss in detail in \rapp{accs}.  This is exactly the syntax used
in~\cite{DBLP:conf/concur/Selinger97,DBLP:journals/iandc/BorealeNP02},
%\ilacom{I put only the references to
%  ~\cite{DBLP:conf/concur/Selinger97}
%  and~\cite{DBLP:journals/iandc/BorealeNP02} here, taking off the
%  reference to~\cite{sangiorgi} that was not appropriate to my view}
%the only difference being that we use
%recursive definitions instead of replication.
without the operators of restriction and relabelling.
Here the syntactic
category $g$ defines \emph{guards}, \ie the terms that may be used as
arguments for the $+$ operator.  Note that, apart from $\Nil$, only
input-prefixed and $\tau$-prefixed terms are allowed as guards, and
that the output prefix operator is replaced by \emph{atoms} $\out{a}$.
%% For instance we will use \ACCS in \rexa{pierre}.
% \ilacom{I think I said this already: in the syntax of \ACCS given
%   in~\rfig{syntax-processes}, the recursive construct, namely the two
%   productions $\rec{p}$ and $x$, should be in the syntactic category
%   of processes and not in that of guards. Otherwise one can write
%   terms such as $g = \rec{\out{a}} + \send{a}.p$, or even worse, terms
%   like $g' = (\rec{\out{a}}\Par \rec{\out{b}}) \,+\, \send{a}.p$, which
%   clearly we do not want to have. See for instance the paper on
%   asynchronous bisimulation [5] page 293, or Sangiorgi's book page
%   191, where the syntactic category $g$ is denoted $M$, and
%   corresponds to input and $\tau$ guarded sums, while the construct
%   for recursive processes, which is replication there, belongs to the
%   syntactic category of processes.}
In fact, this syntax is
completely justified by Selinger axioms, which, as we argued above,
specify that outputs cannot cause any other action, nor be in
conflict with it.

%%% LONG VERSION
%%% Indeed, \ACCS
%the core language in \rfig{syntax-processes}
%%%can be viewed as a syntax for Selinger LTSs.






\begin{figure}
  \hrulefill
%  \scalebox{.8}{%
  \begin{center}
    \begin{tikzcd}
      p
      \arrow[d, dash, dotted, "{\simeq}" description]
      &
      \phantom{p'}
      \\
      q
      \arrow[r, "\alpha"]
      &
      q'
    \end{tikzcd}
    $\Rightarrow$
    \begin{tikzcd}
      p
      \arrow[r, "\alpha"]
      \arrow[d, dash, dotted, "{\simeq}" description]
      &
      p' \arrow[d, dash, dotted, "{\simeq}" description]
      \\
      q \arrow[r, "\alpha"]
      &
      q'
    \end{tikzcd}
  \end{center}
    \vspace{-1em}
 % }
  \caption{Axiom stating that equivalence $\simeq$ is compatible with
    a transition relation.}
\label{fig:Axiom-LtsEq}
\hrulefill
\end{figure}



 \begin{definition}[Transition sequence] %[\coqTS{iexec_from}]
   \label{def:inf-transition-sequence}
   Given an LTS  $\lts{ \States }{ L }{ \st{} }$ and a state $\state_0 \in
  \States$, a \emph{transition sequence} of $\state_0$ is a finite or infinite
  sequence of the form $\state_0 \alpha_1 \state_1 \alpha_2
  \state_2 \cdots$ with $\state_i \in \States$ and $\alpha_i \in L$, and
  such that, for every $n \geq 1$ such that $p_n$ is in the sequence we have
  $\state_{n-1} \stx{\alpha_n} \state_{n}$.
~\hfill$\blacksquare$
 \end{definition}
 \noindent
 If a transition sequence %$\eta$
 is made only of  $\tau$-transitions, 
 it is called a {\em computation} by abuse of notation, the idea being that
 usually $\tau$-steps are related to reduction steps via the Harmony
 lemma.

We give now an example that illustrates the use of the testing
machinery in our asynchronous setting. This is also a counter-example
to the completeness of the alternative preorder
proposed in~\cite{DBLP:conf/fsttcs/CastellaniH98}, as discussed
in detail in~\rapp{counterexample}.




The issues brought about by the contextuality of \rdef{testleq},
though, hinder showing general properties of~$\testleqS$.
Consider the following form of code hoisting:
  \begin{equation}
    \label{eq:mailbox-hoisting}
     \tau.(\co{\aa} \Par \co{b}) \extc
     \tau.(\co{\aa} \Par \co{c}) \testleqS \co{\aa} \Par (\tau.\co{b} \extc
     \tau.\co{c})
  \end{equation}
  If we see the above nondeterministic sums as representing the two
  branches of a conditional statement, this refinement corresponds to
  hoisting the shared action $\co{a}$ before the conditional
  statement, a common compiler optimisation.
%
This motivates the study of alternative characterisations for~$\testleqS$, and
in the rest of the paper we present several preorders that fit the purpose, in
particular the coinductive preorder~$\coindleq$, which we will use to establish
\req{mailbox-hoisting} in~\rsec{coind-char}.


%\gb{Give references to the definitions in appendix H. Everybody OK ?}
We conclude this section by recalling auxiliary and rather standard
notions: given an LTS $\lts{\States}{L}{\st{}}$,
the weak transition relation $\state \wt{ \trace } \stateA $,
where $ \trace \in\Actfin$,
is defined via the rules
\begin{description}
\item[\rname{wt-refl}]
  $\state \wt{\varepsilon} \state$
\item[\rname{wt-tau}]
  $\state \wt{ \trace } \stateB$ if $\state\st{\tau}\stateA$
  and $\stateA \wt{ \trace } \stateB$
\item[\rname{wt-mu}]
  $\state \wt{\mu.s} \stateB$ if $\state \st{\mu} \stateA$
  and $\stateA \wt{\trace} \stateB$
\end{description}
We write $ \state \wt{ \trace }  $ to mean  $\exists \stateA \suchthat \state
\wt{ \trace } \stateA$.
% , where $\trace \in \Actfin$.

%% WHERE IS THIS USED  IN THE RUNNING TEXT ?
%% We let $\str{ \I }$ % (\coqConv{str})
%% be defined as the set of all permutations of the elements of $\I$.
%% For instance $ \str{
%%   \mset{ a, a, b }}  = \set{ a.a.b, a.b.a, b.a.a }$.
%Plainly, $ p \wt{ \emptyMset } q$ if and only if $ p \wt{ \varepsilon } q$.

%{\bfseries Convergence along traces}

\renewcommand{\stateA}{p'}
%Given an LTS in which $\tau$ transitions represent computation steps,
%Given an LTS $\lts{\States}{L}{\st{}}$,
We write $\state \conv$ and say that {\em $\state$ converges} if every
computation of~$\state$ is finite, and we lift the convergence predicate
to finite traces by letting the relation
${\cnvalong} \subseteq \States \times \Actfin$ be the least one that
satisfies the following rules% (\coqConv{cnv}),
\begin{description}
\item[\cnvepsilon] $\state \cnvalong \varepsilon$ if $\state \conv$,
\item[\cnvmu] $ \state \cnvalong \mu.\trace $ if $p \conv$ and
  $\state \wt{\mu} \stateA \implies \stateA \cnvalong \trace$.
\end{description}



\leaveout{
\begin{table}
  \hrulefill
\begin{center}
\begin{tabular}{lcl}
%$ \state \st{ \alpha }$ & means & $\exists \stateA \suchthat \state \st{\alpha} \stateA$,\\
$ \state_0 \stx{ \alpha_0 \ldots \alpha_{n-1} } \state_n$ & means & $ \exists \state_1\ldots \state_n \suchthat \state_0 \st{ \alpha_0 } \state_1  \cdots \st{ \alpha_{n-1} } \state_n$, \\
   $ \state \stx{ \trace } $ & means &
  $\exists
                                                            \stateA \suchthat
                                                            \state \stx{ \trace }
                                     \stateA$,  where $\trace \in \Acttau^+$,
  \\
% $ \state \wt{ \trace }  $ & means & $\exists \stateA \suchthat \state
%                                     \wt{ \trace } \stateA$, where $\trace \in
%                                    \Actfin$,
%\\
  %% $ \state \wt{ X } \stateA $ & means & $\exists \trace \in X \suchthat \state \wt{ \trace } \stateA
  %% $, where $X \subseteq \Actfin$,
  %% \\
  %% $\state \wt{\I} \stateA$ & means & $\exists \trace \in \str{\I} \suchthat \state \wt{ \trace } \stateA$,
  %% \\
  %% $ \state \wt{\I} $ & means & $\exists \stateA. \state
  %% \wt{\I} \stateA$%,
  %% \\[5pt]
  %%  $X \conv$ & means &  $\forall \state \in X \suchthat\state
  %% \conv$,
  %% \\[5pt]
  %% $ X \cnvalong \trace $ & means & $\forall \state \in X
  %% \suchthat \state \cnvalong \trace $
\end{tabular}
\end{center}
\bigskip
\caption{Notational conventions}
\hrulefill
\label{tab:notation}
\end{table}
}


%% \pl{
%% Traces of output actions have no impact on the stability of processes.
%% %% on their input actions.%, and on their being (not) $\goodSym$. %%
%% \begin{lemma}
%%   \label{lem:st-wtout-st}  %% \label{lem:st-wtout-inp} %%
%%   For all $\server, \server' \in \States$ and trace $\trace \in \co{\Names}^\star$ such that
%%   $\server \stable$ and $\server \wt{ \trace } \server'$
%%   %% \begin{enumerate} %%
%%   then %(\coqLTS{st_wtout_st})
%%   $\server' \stable$,
%%   %% \item %(\coqLTS{st_wtout_inp})                                                     %%
%%   %%   for every $\aa \in \Names$,                                                      %%
%%   %%   $\server \stable$, $\server \st{\aa}$ and $\server \wt{ \trace } \server'$ imply %%
%%   %%   $\server' \st{\aa}$.                                                             %%
%%   and %(\coqLTS{st_wtout_inp})
%%   for every $\aa \in \Names$, $\server \Nst{\aa}$ implies $\server' \Nst{\aa}$.
%%   %% \end{enumerate} %%
%% \end{lemma}
%% }

%% By assumption, outputs preserve the predicate~$\goodSym$. \ilacom{Put
%%   somewhere else?}



  To understand the next section, one should
  keep in mind that all the predicates defined
  above have an implicit parameter: the LTS of programs. % over which we predicate.
  By changing this parameter, we may change the meaning of the
  predicates.
  % \TODO{I do not understand why the processes $\tau.\Nil$ is used.
  % Should we not discuss just $\Omega$ ?}
  % For instance, letting $\Omega$ be the~\ACCS process
  %   $\rec{\tau. x}$, in the standard LTS
  % $\lts{\ACCS}{\st{}}{\Acttau}$ we have $ \tau.\Nil \st{ \tau } \Nil$
  % and $\lnot (\Omega \conv)$, while in the LTS $\lts{\ACCS}{ \emptyset
  % }{\Acttau}$ we have $\tau.\Nil \Nst{ \tau }$ and $\Omega \conv$.%
  % \footnote{\gb{$\Omega \Nst{\tau}$ and thus $\Omega
  %     \conv$}. \ilacom{In fact, this holds for any $p$ in the
  %     second LTS.}}
  For instance, letting~$\Omega$ be the~\ACCS process~$\rec{\tau. x}$, in the standard LTS
  $\lts{\ACCS}{\st{}}{\Acttau}$ we have~$ \Omega \st{ \tau } \Omega$
  and $\lnot (\Omega \conv)$, while in the LTS $\lts{\ACCS}{ \emptyset
  }{\Acttau}$ we have $\Omega \Nst{\tau}\,$ and thus $\Omega \conv$.
  %
  In other words, the {\em same} predicates can be applied to
  different LTSs, and since the alternative characterisations
  of~$\testleqS$ are defined using such predicates, they
  can relate different LTSs.
