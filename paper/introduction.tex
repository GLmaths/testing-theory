\newcommand{\erlang}{\href{https://www.erlang.org/faq/introduction.html}{\textsf{Erlang}}\xspace}
\newcommand{\elixir}{\href{https://elixir-lang.org/}{\textsf{Elixir}}\xspace}


\section{Introduction}
\label{sec:intro}

\paragraph{Software update is a critical operation.}
Correct operations of software systems are jeopardised by an
apparently innocuous operation:
software update. Considering the following cases. %
%%% ORDERED WRT TIME %%%
On August $1$st $2012$ an update of the trading software by the Knight
Capital Group caused a major stock market disruption, making the
company lose~$400$ million US dollars (USD) and go bankrupt in
nearly~$45$ minutes \cite{knightmare,WkKnightmare}.
On January $24$th $2014$ a configuration update caused a~$25$ minutes
outage of Google services \cite{WkGoogle}.
On October $4$th $2021$ an update in the DNS tables at Facebook has led
to more than~$7$ hours of downtime in the company services (WhatsApp,
Instagram, Facebook), and a loss of at least~$60$ million
dollars in revenue \cite{facebook}.
On September $6$th $2023$ a software update at
United Airlines made it to the news for it grounded for one day
essentially all of the carrier planes in the
US~\cite{update-grounded-flights}.
On July $19$th $2024$ the company \href{https://www.crowdstrike.com/}{CrowdStrike} 
distributed a faulty software update that caused a global outage
in airlines, banks, and media for an estimated total loss of~$10$
billions USD \cite{WkCrowd}.



\paragraph{Why asynchrony ?}
Asynchrony is intrinsic to multi-cores CPU, because
the usual computer memory (i.e. the RAM) is asynchronous:
a program can always read and write the memory cells it
has access to. This is the very basis for shared-memory concurrency.
Owing to the asynchronous behaviour of memory, ad-hoc assembly
instructions like \textsc{cmpxchgl} \cite{WkCAS} are required to
synchronise concurrent programs which, at present, are
the only manner to harness the sheer power of multi-cores CPU
\cite{doi:10.1126/science.aam9744}.
As for languages, the Linux kernel API supports asynchronous process execution via a workqueue \cite{workqueue}, and offers ad-hoc
constructs for locking \cite{locktypes}.
\textsc{Python} and \textsc{Javascript} offer developers the
\textsc{await} (i.e. async wait) construct to spawn asynchronous
computations. \textsc{Java} offers a similar mechanism via the 
\texttt{Future} interface, which represents the result of asynchronous
function calls \cite{java.future}.
Asynchrony is such a fundamental phenomenon that it is studied also
in $\lambda$-calculus and the foundations of PL \cite{DBLP:journals/lmcs/AhmanP24}.
\gb{Add pointers to Go and to asynchronous programming in Angular,
  which is heavily used at Docaposte (private communication).}

%%%
Asynchrony is intrinsic also to
the beating heart of distributed systems: message-passing software
\gb{Cite also lamport and lynch.}
\cite{10.5555/2517679}.
On the Internet programs interact by storing messages in queues,
and a priori send operations are decoupled from reception ones.
Moreover in networks messages can be lost, corrupted, or received
out of order.
%and the time when messages are actually read is not know a priori.
Developing software for distributed systems is thus notoriously
hard. PLs exists, that have been designed to streamline message-passing.
Two successful cases are \erlang\ and \elixir. They both rely on {\em
  actors}, i.e. computational units that
comprise an identifier, some code, and a {\em private mailbox} (i.e. a queue),
used for communication with other actors \cite{DBLP:journals/jfp/AghaMST97}.






%% Code refactoring is a routine task to develop or update software, and
%% it requires methods to ensure that a program~$\serverA$ can be safely
%% replaced by a program~$\serverB$.  One way to address this issue is
%% via refinement relations, \ie preorders.  For programming languages,
%% the most well-known one is Morris \emph{extensional} preorder
%% \cite[pag.~$50$]{morris}, defined by letting~$p \leq q$ if for all
%% contexts~$C$, whenever~$C[p]$ reduces to a normal form~$N$,
%% then~$C[q]$ also reduces to~$N$.

%% \paragraph{Comparing servers}
%% This paper studies a version of Morris preorder for
%% \nondeterministic asynchronous \svrclt systems.
%% In this setting it is natural to reformulate the preorder by replacing
%% reduction to normal forms (\ie termination) with a suitable
%% \emph{liveness} property.
%% Let~$\csys{ \server }{ \client }$ denote a {\em \svrclt\ system},
%% that is a parallel composition in which the identities of the
%% server~$\server$ and the client~$\client$ are distinguished, and
%% whose computations have the form
%% $
%% \csys{\server~}{~\client} =
%% \csys{ \server_0 }{ \client_0 } \st{ }
%% \csys{ \server_1 }{ \client_1 } \st{ }
%% \csys{ \server_2 }{ \client_2 } \st{ } \ldots,
%% $
%% where each step represents either an internal computation
%% of one of the two components, or an interaction between them.
%% Interactions correspond to handshakes, where
%% two components ready to perform matching input/output actions
%% advance together.
%% We express liveness by saying that  $\server \text{ \emph{must pass} }
%% \client$, denoted $\Must{ \server }{ \client }$, if in every maximal
%% computation of $\csys{ \server }{ \client
%% }$ there exists a state $\csys{ \server_i}{ \client_i}$ such that
%% $\good{\client_i}$, where~$\goodSym$ is a decidable predicate
%%  indicating that the client has reached a successful state.
%% Servers are then compared according to their capacity to
%% satisfy clients, \ie via contexts of the form~$\csys{[-]}{\client}$
%% and the predicate~$\opMust$.
%% %namely to lead clients to successful states, \ie via
%% %In other words, servers are compared
%% %via contexts of the form~$\csys{[-]}{\client}$.
%% %, as argued also by \cite{DBLP:phd/us/Thati03}.
%% Morris preorder %, when restricted to computations leading to
%% %successful states,
%% then becomes the \mustpreorder\
%% by De Nicola and Hennessy~\cite{DBLP:journals/tcs/NicolaH84} :
%% %\begin{equation}
%% %  \label{eq:must-preorder}
%% %%
%% $
%%   \serverA \testleqS \serverB \text{ when } \forall \client \wehavethat
%%   \Must{\serverA}{\client} \implies
%%   \Must{\serverB}{\client}.
%%   $
%% %%\end{equation}


%% \paragraph{Advantages}
%%   The \mustpreorder is by definition liveness preserving,
%%   because $\Must{ \server }{ \client }$ literally means that
%%   ``in every execution something good must happen (on the client
%%   side)''.  Results on~$\testleqS$ thus shed light on
%%   liveness-preserving program transformations.

%%   The~\mustpreorder is independent of any particular calculus,
%%   as its definition requires simply
%%   (1) a reduction semantics for the parallel composition
%%   $\csys{ \server }{ \client }$, and (2)
%%   a predicate $\goodSym$ over programs.
%%   %%% LONG VERSION
%%   %% We thus do not fix any particular calculus:
%%   %% we assume a way of describing how servers and clients interact
%%   %% with the environment, and use it to define the semantics of $\csys{
%%   %%   - }{ - }$.
%%   %%As a result,
%%   Hence~$\testleqS$
%%   % the relation~$\testleqS$
%%   % lets us compare software components
%%   may relate servers written in different languages. For instance, servers written in
%%   \textsc{OCaml} may be compared to servers written in \textsc{Java}
%%   according to clients written in \textsc{Python}, because all
%%  these languages use the same basic protocols for communication.
%%   % all these languages communicate using the same basic protocols.
%%   %%VERY DODGY STATEMENT:  that we are able to model.

%% \paragraph{Drawback}
%%   The definition of the \mustpreorder is {\em contextual}: proving
%%   $\serverA~\testleqS~\serverB$ requires analysing an {\em
%%   infinite} amount of clients, and so the definition of
%% the preorder does not entail an effective proof method.
%% A solution to this problem is to define an {\em alternative (semantic)
%%   characterisation} of the preorder~$\testleqS$, \ie a
%% preorder~$\altleq$ that coincides with~$\testleqS$
%% and does away with the universal quantification over clients (\ie contexts).
%% In {\em synchronous} settings, i.e. when both input and output
%% actions are blocking, such alternative characterisations have been thoroughly
%% investigated, typically via a behavioural approach based on labelled transition
%% systems.


%% \begin{figure}[t]
%%   \hrulefill
%%   \begin{center}
%%     \begin{minipage}{4cm}
%%         \centering
%%       \begin{tikzpicture}
%%         \node[state,scale=0.8] (s1) at (6,0) {$\server_0$};
%%         \node[state,scale=0.8,below of=s1,left of=s1] (s2) {$\server_1$};
%%         \node[state,scale=0.8,below of =s1,right  of=s1] (s3) {$\server_2$};
%%         \node[state,scale=0.8,below of=s2] (s4) {$\server_3$};
%%         \node[state,scale=0.8,below of=s3] (s5) {$\server_4$};

%%         \node[scale=0.8, below of = s5] (dummy) {$$};

%%         \path[->]
%%         (s1) edge node [above left,scale=0.8] {$\texttt{str}$} (s2)
%%         (s1) edge node [above right,scale=0.8] {$\texttt{float}$} (s3)
%%         (s2) edge node [left,scale=0.8] {$\co{\texttt{int}}$} (s4)
%%         (s3) edge node [right,scale=0.8] {$\co{\texttt{long}}$} (s5);
%%       \end{tikzpicture}
%%       \end{minipage}%
%%       \begin{minipage}{4cm}
%%         \centering\vskip-0.95em
%%       \begin{tikzpicture}
%%         \node[state,scale=0.8] (s0) at (0,0) {$\client_0$};
%%         \node[state,dashed,scale=0.8,below right = +15pt and +15pt of s0] (s1) {$\client_2$};
%%         \node[state,scale=0.8,below left = +15pt and +15pt of s0] (s2) {$\client_1$};
%%         \node[state,dashed,scale=0.8,below right = +15pt and +15pt of s2] (s3) {$\client_3$};

%%         \path[->]
%%         (s0) edge node [above left,scale=0.8] {$\co{\texttt{str}}$} (s2)
%%         (s0) edge node [above right,scale=0.8] {$\texttt{int}$} (s1)
%%         (s2) edge node [below left,scale=0.8] {$\texttt{int}$} (s3)
%%         (s1) edge node [below right,scale=0.8] {$\co{\texttt{str}}$} (s3);
%%     \end{tikzpicture}
%%   \end{minipage}
%%   \end{center}
%%   \vskip-1.5em
%%   \caption{The behaviours of a server $\server_0$ and of a client $\client_0$.}
%%   \label{fig:first-example}
%%   \hrulefill
%% \end{figure}

%% \paragraph{Labelled transition systems}
%% A program~$\serverA$ is associated with
%% % $\ltsof{\serverA}$,
%% a labelled transition system (LTS) representing its behaviour,
%%  which we denote by $\ltsof{\serverA}$.
%% %
%% \rfig{first-example} presents two instances of LTSs, where
%% transitions are labelled by input actions such as $\texttt{str}$, %$\aa$,
%% output actions such as $\co{\texttt{str}}$, or the internal action $\tau$ (not
%% featured in~Figure~\ref{fig:first-example}), while dotted nodes represent
%% successful states, \ie those satisfying the predicate~$\goodSym$. There, the
%% server~$\server_0$ is ready to input either a string or a float.
%% %
%% It is the environment that, by offering an output of
%% either type, will make~$\server$ move to either~$\server_1$
%% or~$\server_2$.
%% %
%% The client~$\client_0$, on the other hand, is ready to either output a
%% string, or input an integer. The input ${\tt int}$ makes the client
%% move to the %$\goodSym$
%% successful state~$\client_2$, while the output $\co{\tt{str}}$ makes
%% the client move to the state $\client_1$, where it can still perform
%% the input ${\tt int}$ to reach the %$\goodSym$
%% successful state~$\client_3$. In an asynchronous setting, output
%% transitions enjoy a 
%% commutativity property on which we will return later.
%% %
%% Programs $\serverA$ are usually associated with their behaviours
%% $\ltsof{\serverA}$ via inferences rules that we omit in the main body of the
%% paper, as they are standard.

%% \paragraph{Alternative preorders for synchrony} 

%% Program behaviours, \ie~LTSs, are used to define the
%% alternative preorders for~$\testleqS$
%% following one of two different
%% approaches: \MustSets or \AcceptanceSets.

%% Both approaches were
%% originally proposed for Milner's
%% Calculus of Communicating Systems ($\CCS$)~\cite{DBLP:books/daglib/0098267},
%% where communication is \emph{synchronous}.
%% %
%% The first alternative preorder, which we denote by~$\msleq$, was put
%% forth by De Nicola~\cite{DBLP:journals/tcs/NicolaH84}, and it
%% compares server behaviours according to their \MustSets, \ie~the sets of
%% actions that they may perform.
%% %
%% The second alternative preorder, which we denote by~$\asleq$, was put
%% forth by Hennessy~\cite{DBLP:books/daglib/0066919}, and it compares the
%% \AcceptanceSets of servers, \ie~how servers can be moved out of their
%% potentially deadlocked states.
%% %
%% Both these preorders characterise~$\testleqS$ in the
%% following sense:
%% %
%% \begin{align}
%%       \label{eq:bhv-mustset-characterisation}
%%   \forall \serverA , \serverB \in \CCS \wehavethat\; & \serverA \testleqS \serverB
%%   \text{ iff } \ltsof{\serverA} \msleq \ltsof{\serverB}
%%   \\
%%     \label{eq:bhv-accset-characterisation}
%%   \forall \serverA , \serverB \in \CCS \wehavethat\; & \serverA \testleqS \serverB
%%   \text{ iff } \ltsof{\serverA} \asleq \ltsof{\serverB}
%% \end{align}
%% %
%% While these
%%   alternative preorders do away with the universal quantification
%% over clients, they are not practical to use directly, as they still universally
%% quantify over (finite) traces of actions.
%% %
%% A more practical approach \cite{DBLP:journals/jacm/AcetoH92} is to use a
%% coinductively defined preorder~$\coindleq$ based on~$\asleq$
%% \cite{DBLP:journals/jacm/AcetoH92,DBLP:conf/concur/LaneveP07,DBLP:journals/mscs/BernardiH16}.
%% %
%% It has two advantages: first, its definition quantifies universally on single
%% actions, and it allows the user to use standard coinductive methods, as found in
%% the literature on bisimulation.
%% %
%% In the case where the LTS is image-finite, such as for CCS and most process
%% calculi, the coinductive preorder is sound and complete:
%% \begin{equation}
%%       \label{eq:bhv-coind-characterisation}
%%   \forall \serverA , \serverB \in \CCS \wehavethat\; \serverA \testleqS \serverB
%%   \text{ iff } \ltsof{\serverA} \coindleq \ltsof{\serverB}
%% \end{equation}
%
% Note that in Equation~(\ref{eq:bhv-coind-characterisation}) the LHS of
% the inequality is a set of servers rather than a single server. The
% reason is that in our proof of soundness we use an LTS whose
% states are sets of processes, since this helps us to deal with server
% nondeterminism.



%% \gb{%
%% {\smaller[.99]
%% $$
%% \begin{array}{|l@{\hskip 1pt}l@{\hskip 2pt}c@{\hskip 2pt}l|l@{\hskip 1pt}l@{\hskip 2pt}c@{\hskip 2pt}l|}
%%   \hline
%%   \forall \serverA , \serverB \in \CCS \wehavethat & \serverA \testleqS \serverB
%%   & \text{ iff } & \ltsof{\serverA} \asleq \ltsof{\serverB}
%%   &
%%    \forall \serverA , \serverB \in \obaFB
%%     \wehavethat& 
%%     \serverA \testleqS \serverB
%%     &\text{ iff }&
%%     \liftFW{\serverA} \msleq \liftFW{\serverB}
%% \\
%%   \label{eq:bhv-mustset-characterisation}
%%   \forall \serverA , \serverB \in \CCS \wehavethat & \serverA \testleqS \serverB
%%   & \text{ iff } & \ltsof{\serverA} \msleq \ltsof{\serverB}
%%   &
%%   \forall \serverA , \serverB \in \obaFB
%%     \wehavethat&
%%     \serverA \testleqS \serverB
%%     &\text{ iff }&
%%     \liftFW{\serverA} \asleq \liftFW{\serverB}
%%     \\[2pt]
%%     \hline
%%     \multicolumn{4}{c}{\text{(a) Seminal results}}
%%     &
%%     \multicolumn{4}{c}{\text{(b) Novel results}}
%% \end{array}
%% $$
%% }
%% }%% \gb

%For instance \cite{DBLP:journals/iandc/BorealeNP02} use it
%in an asynchronous settings, \ilacom{I would not mention asynchronous
%  approaches here. I would only do it after we start talking about the
%  asynchronous case, namely after the paragraph ``On the Internet,
%  though\ldots''} and
%% REDUNDANT FOR WE ALREADY SAID IT ABOVE
%% In both~(\ref{eq:bhv-accset-characterisation}) and~(\ref{eq:bhv-mustset-characterisation}),
%% $\CCS$ is Milner's Calculus of Communicating Systems
%% \cite{DBLP:books/daglib/0098267}, and thus~$\serverA$ and~$\serverB$
%% are syntactic terms.
%%   There the server~$\server$ is \ila{initially} in a {\em stable state}: it
%% cannot perform any $\tau$ move, but \ila{it} is ready to input either a string
%% or a float, and it is the environment that, by offering an output of
%% either type, will make~$\server$ move to a different state.
%% Hence,~$\server_0$ models an {\em external} choice. The
%% client~$\client$, on the other hand, can either output a string, or
%% move to a different state via an internal computation.
%This is a form of {\em internal choice}. \ilacom{To my view, this does
%  not represent an internal choice - which should have both outcoming
%  transitions labelled by $\tau$ - but rather a parallel composition
%  of the output $\co{\texttt{str}}$ with the action $\tau$, as
%  witnessed by the fact that the LTS is diamond shaped (cf axiom
%  \ila{\outputtau).}}
%can interact
  %In either case, in each maximal computation of $\csys{ \server }{ \client }$ the client will eventually reach a successful state.}

%%%%%%%%% ILARIA: Logical characterisation, commented off 23/11/23

% {\em Logical} characterisations of~$\testleqS$, instead,
% require defining when a program~$\server$ models a certain
% formula~$\phi$, denoted $\server \models \phi$, where
% formulae belong typically to the recursive Hennessy-Milner
% logic, \ie the modal $\mu$-calculus, and the
% characterisations essentially identify the fragment~$L$
% of this logic, which is necessary and sufficient to capture
% the contextual preorder:
% \begin{equation}
%   \label{eq:logical-characterisation}
%   \forall \serverA , \serverB \in \CCS \wehavethat
%   \serverA \testleqS \serverB
%   \text{ iff }  (\forall \phi \in L \wehavethat \serverA \models \phi \implies \serverB \models \phi)
% \end{equation}
% These characterisations, given in Theorem 4.1 by
% \cite{DBLP:journals/jacm/AcetoH92} and indirectly by
% \cite{DBLP:journals/corr/abs-1011-6438},
% %are close in spirit to the
% %well-known theorem by \cite{DBLP:journals/jacm/HennessyM85},  and they
% identify the behavioural proprieties that are invariant under code refactoring done via~$\testleqS$.



%% \paragraph{Asynchrony} %
%% In distributed systems, communication is inherently
%% asynchronous. For instance, the standard TCP transmission on the
%% Internet is asynchronous.  Actor languages like \textsc{Elixir} and
%% \textsc{Erlang} implement asynchrony via mailboxes, and both
%% \textsc{Python} and \textsc{JavaScript} offer developers the
%% constructs \textsc{async/wait}, to return promises (of results) or
%% wait for them.  In this paper we model asynchrony via
%% \emph{output-buffered agents with feedback}, as introduced by
%% Selinger~\cite{DBLP:conf/concur/Selinger97}.  These are LTSs obeying
%% the axioms in \rfig{axioms}, where~$\aa$ denotes an input
%% action,~$\co{\aa}$ denotes an output action,~$\tau$ denotes the
%% internal action, and~$\alpha$ ranges over all these actions.  For
%% instance, the \outputcommutativity axiom states that an output
%% $\co{a}$ % $\co{a}$ that is followed by any action~$\alpha$,
%% can always be postponed: if $\co{a}$ is followed by any
%% action~$\alpha$, it can commute with it.  In other words, outputs are
%% non-blocking, as illustrated by the LTS for~$\client_0$ in
%% \rfig{first-example}.
%% We defer a more detailed discussion of these axioms in
%% to \rsec{preliminaries}.
%% \paragraph{Technical difficulties} % due to asynchrony.}
%% The practical importance of asynchrony motivates a % suitable
%% specific study of~$\testleqS$. Efforts in this direction have
%% been made, all of which focussed on process calculi
%% \cite{DBLP:conf/fsttcs/CastellaniH98,DBLP:journals/iandc/BorealeNP02,DBLP:phd/us/Thati03,DBLP:journals/jlp/Hennessy05},
%% while the axioms in \rfig{axioms} apply to LTSs.
%% % The axioms in \rfig{axioms}, though, create an asymmetry between output
%% % and input actions, because they % force
%% % impose properties only over the outputs.
%% Note that these axioms impose conditions
%%   only over outputs, and this asymmetric treatment of inputs and outputs
%% substantially complicates the proofs of completeness and soundness of
%% the alternative characterisations of~$\testleqS$.
%% LONG VERSION
%% For instance, the phenomenon leaps out in the completeness proofs of alternative
%% characterisations, for their arguments depend on the contexts (\ie
%% clients), and the standard reasoning requires clients with blocking
%% outputs, that do not exist in the asynchronous setting.  As a
%% consequence, the results in (\ref{eq:bhv-mustset-characterisation})
%% and (\ref{eq:bhv-accset-characterisation}) do not hold in settings
%% where programs communicate by modifying a shared unordered buffer
%% \cite{DBLP:conf/concur/Selinger97,DBLP:conf/ecoop/HondaT91,
%%   boudol:inria-00076939}.
% and hence outputs are {\em non-blocking}.
%% For instance, \cite{DBLP:conf/fsttcs/CastellaniH98}
%% give simple counterexamples to~(\ref{eq:bhv-accset-characterisation})
%% in the setting of asynchronous \CCS (ACCS). There $ {\tt str}.\Nil
%% \testleqS \Nil $, \ie a server that does nothing is as good as a
%% server than can input a  string, while $ {\tt str}.\Nil \not \asleq
%% \Nil $.
%As for
%% To underline the subtleties due to asynchrony, we note that the completeness
%% result for asynchronous
%%   \CCS given by Castellani and Hennessy
%%   in~\cite{DBLP:conf/fsttcs/CastellaniH98},
%%   and subsequently extended to the $\pi$-calculus by 
%%   Hennessy~\cite{DBLP:journals/jlp/Hennessy05},
  %% is false (see \rapp{counterexample}).

% the technical work to obtain
% completeness (lemmas 3.26 and 3.27 there) to the reader.
%% LONG VERSION
%% Similarly
%% for Theorem 5.3 of \cite{DBLP:phd/us/Thati03}, which is presented as
%% a ``simple adaptation of the [\ldots] characterisation [\ldots] over
%% asynchronous CCS \cite{DBLP:conf/fsttcs/CastellaniH98}'', and
%% therefore not provided with a proof.  Instead,
%% \cite{DBLP:journals/iandc/BorealeNP02} change the definition of the
%% alternative preorder to arrive at a characterisation.


%% \footnote{It should be noted also that the behavioural preorder of
%% \cite{DBLP:conf/fsttcs/CastellaniH98} relies on acceptance sets,
%% while the one given in  \cite[Definition 5.8]{DBLP:phd/us/Thati03}
%% relies on $\Must$-sets, so anyhow the proof of Theorem 5.3 should not
%% follow from the one by Castelanni and Hennessy, but rather from the
%% one of \cite{DBLP:journals/iandc/BorealeNP02}.}.
%%%%%%%%% ILARIA: moved earlier 23/11/23 %%%%%%%%%%%%%%%%%%%
% On the Internet, though, communication is {\em asynchronous}, because so is
% the standard TCP transmission; actor languages like
% \textsc{Elixir} and \textsc{Erlang} implement asynchrony via mailboxes, and
% both \textsc{Python} and \textsc{Javascript} offer developers the \textsc{async/wait}
% constructs, to return promises (of results) or to wait for them.
% The reality is thus in stark contrast with the state in which the
% existing theory of~$\testleqS$ lays, and calls for a solid study of
% this preorder in an asynchronous setting, via tools fit to make us
% tame the lengthy (and at times tedious) proofs about semantics of
% programming languages.
% To provide such a foundation, we mechanise our work in the Coq proof
% assistant.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Though we propose a minor generalisation of Selinger axioms, 
this paper remains chiefly analytical: it studies in depth axioms
on LTS, to prove their logical independence, and to improve
the results of \cite{bernardi2025}.
The corollaries of our analysis is a unique characterisation
of the \mustpreorder\ for different calculi:
CCS with value passing, %
its asynchronous variant, %
the core join calculus. %


\subsection*{Contributions} 
This paper
\begin{itemize}
  
\item Proves that the results of \cite{bernardi2025} hold independently
  from the nature of the actions used in the LTS.
  The information sufficient and necessary for the proofs
  to work is whether an action is blocking or non-blocking:
  the nature of actions is irrelevant.

  \item %
  Showcases the approach suggested in \cite{bernardi2025}
  to obtain a proof method for the \mustpreorder.
  It is sufficient to give a calculus an LTS such that
  \begin{enumerate}
    \item the Harmony Lemma holds,
    \item non-blocking actions satisfy Selinger axioms,
    \item contexts can be defined, that satisfy the completeness
      axioms of \cite{bernardi2025}.
  \end{enumerate}
  We do so for three different calculi.
  Obtains the results of \cite{}, the theorems by De Nicola and
  Hennessy (here \ref{AAA} and \ref{AAA}), and an analogous result for
  Input Buffered Agents as corollaries of our more general theorems
  (\ref{} and \ref{}).
  Note in passing that this is the first constructive and machine-checked
  account of De Nicola and Hennessy's results for synchronous calculi.
  
 \item %
  Characterises the traces that are
  actually relevant in the
  completeness arguments (\ref{}).
  This reduces the amount of traces to be actually
  accounted for by an algorithm.

\item %
  Provides a novel co-inductive characterisation of
  the \mustpreorder, which reduces the amount of actions
  to be check in order to prove that a program $\serverB$ refines
  a program $\serverA$ (\ref{}).
  Showcases how to employ this proof method discussing a concrete
  example in Coq. (\ref{}).
\end{itemize}
