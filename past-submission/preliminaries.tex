%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\outputcommutativity  &  \outputfeedback & \outputconfluence

\begin{figure}[t]
  \hrulefill
  %     (* further details omitted for readability. *)
  \begin{minted}{coq}
    Class Sts (A: Type) := MkSts {
      sts_step: A → A → Prop;
      sts_stable: A → Prop; }.

    Inductive ExtAct (A: Type) :=     Inductive Act (A: Type) :=
    | ActIn (a: A) | ActOut (a: A).   | ActExt (ext: ExtAct A) | τ.

    Class Label (L: Type) :=          Class Lts (A L : Type) `{Label L} := 
    MkLabel {                         MkLts {
     label_eqdec: EqDecision L;        lts_step: A → Act L → A → Prop;
     label_countable: Countable L; }.  lts_outputs: A → finite_set L;
                                       lts_performs: A → (Act L) → Prop; }.
  \end{minted}
    %  lts_state_eqdec: EqDecision A;
  %       lts_stable_decidable: ∀ x ℓ, Decision (lts_stable x ℓ);
  %       lts_step_decidable: ∀ a l b, Decision (lts_step a l b);
  %      lts_outputs_spec1 s1 x s2 : lts_step s1 (ActExt (ActOut x)) s2 → x ∈ lts_outputs s1;
%      lts_outputs_spec2 s1 x : x ∈ lts_outputs s1 → ∃ s2, lts_step s1 (ActExt (ActOut x)) s2;
%      lts_stable_spec1: ∀ x ℓ, ¬ lts_stable x ℓ → { y | lts_step x ℓ y };
%      lts_stable_spec2: ∀ x ℓ, { y | lts_step x ℓ y } → ¬ lts_stable x ℓ;
  \caption{Highlights of our Sts and Lts typeclasses.}
  \label{fig:mechanisation-lts}
  \label{fig:sketch-mechanisation-sts}
  \hrulefill
\end{figure}



%%%% Section START %%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}
\label{sec:preliminaries}
%As hinted in the Introduction,
We model individual programs such as
servers~$\server$ and clients~$\client$ %are modelled
as LTSs obeying Selinger axioms, while client-server systems
$\csys{\server}{\client}$ are modelled as state transition systems
with a reduction semantics. We now formally define this two-level
semantics.
%for programs and systems.

% \ilacom{TODO: Introduce first the sets of names $\Names$ and conames
%   $\overline{\Names}$, representing process inputs and outputs
%   respectively. Then introduce the silent or invisible action $\tau$,
%   and define the set of process actions to be
%   $\Acttau \;\;\eqdef\;\; \Names \uplus \{ \co a \mid a \in \Names \}
%   \uplus \{ \tau \} $. This is the set of actions of CCS and of
%   Selinger LTSs. Then insert the paragraph \emph{Labelled transition
%     systems}, and say that here we assume $L$ to be $\Acttau$.  Now
%   add a paragraph \emph{Client-server systems}, and explain that the
%   STS semantics of systems is derived from the LTS semantics of
%   programs as specified by the rules in Figure~\ref{fig:rules-STS}.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\bfseries Labelled transition systems.}
A \emph{labelled transition system} (LTS) is a triple
$\genlts = \lts{ \States }{ L }{ \st{} }$ where~$\States$ is the set
of states, $L$~is the set of labels
% defined as $
%   L \;\;\eqdef\;\; \Names \cup \{ \co a \mid a \in \Names \} \cup \{ \tau \}
%   $
  and ${\st{}}
  \subseteq \States \times L \times \States$ is the transition
  relation.
  When modelling programs as LTSs, we use transition labels to
  represent program actions. The set of labels in Selinger LTSs has
  the same structure as the set of actions in Milner's calculus \CCS:
  one assumes a set of names~$\Names$, denoting input actions and
  ranged over by~$\aa, \ab, c$, a complementary set of
  conames~$\overline{\Names}$, denoting output actions and ranged over
  by $\co{\aa}, \co{\ab}, \co{c}$, and an \emph{invisible}
  action~$\tau$, representing internal computation.
The set of all actions, ranged over by $\alpha, \beta, \gamma$,
is given by
$\Acttau \;\;\eqdef\;\; \Names \uplus \overline{\Names}
%\{ \co a \mid a \in \Names \}
   \uplus \{ \tau \} $.
We use $\mu, \mu'$ to range over the set of visible actions $\Names
\uplus \overline{\Names}$, and we extend the complementation function
$\co\cdot$ to this set by letting ${\co{\co \aa}} \eqdef \aa$.
In the following, we will always assume $L = \Acttau$.
Once the LTS is fixed, we write %use the infix notation
$\state \st{\alpha} \stateA$ to mean that
$(\state,\alpha,\stateA)~\in~{\st{}}$ and $ \state \st{ \alpha }$
to mean $\exists \stateA \suchthat \state \st{\alpha} \stateA$.
%
% In the sequel, we shall loosely use the terms ``input'' and ``output''
% either for an input/output action or for an input/output transition.
% %(i.e., a transition labelled by an input/output action).
% \ilacom{Take off this sentence?}

% {\em Notation:}
We use $\genlts$ to range over LTSs. To reason
simultaneously on different LTSs, we will use the
symbols~$\genlts_A$ and~$\genlts_B$ to denote respectively
the LTSs~$\lts{\StatesA}{L}{\st{}_A}$ and~$\lts{\StatesB}{L}{\st{}_B}$.


In our mechanisation LTSs are borne out by the typeclass
\lstinline|Lts| in \rfig{mechanisation-lts}. The states of the LTS
have type $\States$, labels have type $L$, and \lstinline|lts_step| is
the characteristic function of the transition relation, which we
assume to be decidable.  We let $O(\state) = \outactions{ \state }$
and $I(\state) = \inactions{ \state}$ be respectively the set of
outputs and the set of inputs of state~$\state$.  % (\coqSyn{outputs_of}, \coqSyn{inputs_of}).
We assume that the set $O(\state)$
% assume that the set of output actions of any state of~$\StatesA$
% is given by the function \lstinline|lts_outputs| and
  is finite for any $\state$.
  % , \ie $\forall p \in \States . |O(p)| \in \N$.
  In our mechanisation, the set
$O(\state)$ is rendered by the function \lstinline|lts_outputs|,
and we shall also use a function \lstinline|lts_performs| that
% We also assume that the function \lstinline|lts_performs|
lets us decide whether a state can
perform a transition labelled by a given action.


%%%%% ILARIA: moved this at the end of previous paragraph
%
% {\em Notation:} we use $\genlts$ to range over LTSs. To reason
% simultaneously on different LTSs, we will use the
% symbols~$\genlts_A$ and~$\genlts_B$ to denote respectively
% some LTS~$\lts{\StatesA}{L}{\st{}_A}$ and some LTS~$\lts{\StatesB}{L}{\st{}_B}$.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \ilacom{DO we still need the following?}
% Parallel composition is defined over
% LTSs with the same labels $\lts{\States_1}{L}{\st{}_1}$ and
% $\lts{\States_2}{L}{\st{}_2}$, and describes the transition relation
% of the LTS $\lts{\States_1 \times \States_2}{L}{\st{}}$, where the
% transition relation $\st{}$ is defined in the standard way
% in~\rfig{}.
% This is also the semantics of \svrclt systems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%% ILARIA (14/12/23): Rules adapted from those of ACCS in Appendix


\begin{figure}[t]
\hrulefill
$$
\begin{array}{llllll}
  \stauserver
  &
\begin{prooftree}
{ \server \st{\tau} \server' }
  \justifies
      {\csys{\server}{\client} \st{} \csys{\server'}{\client}}
\end{prooftree}
&
\stauclient&
\begin{prooftree}
  \client \st{\tau} \client'
  \justifies
      {\csys{\server}{\client} \st{} \csys{\server}{\client'}}
\end{prooftree}
&
\scom&
\begin{prooftree}
  \server\st{ \mu } \server' \quad \client \st{\co{ \mu }} \client'
  \justifies
  \csys{\server}{\client} \st{} \csys{\server'}{\client'}
\end{prooftree}
\end{array}
$$
\caption{The STS of server-client systems.}
% The metavariables are
% $\aa \in \Names, \co{\aa} \in \overline{\Names}, \mu \in \Act, \and
% \alpha \in \Acttau$.
  \label{fig:rules-STS}
\hrulefill
\end{figure}


{\bfseries Client-server systems.} %
%
%%%%%% ILARIA: shortened for CONCUR
%
% We denote with $\csys{\server}{\client}$ a pair of states
% in which~$\server$ is deemed the server of client~$\client$.
% We call the pair $\csys{\server}{\client}$ a {\em \svrclt} system,
% for short a {\em system}. 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%
%
A {\em \svrclt} system (or {\em system}, for short) is a pair
$\csys{\server}{\client}$ in which~$\server$ is deemed to be the server of
client~$\client$.
%
 %  and we assume a reduction semantics for~$- \llceil -$. For example,
%   if $\server$ and
%   $\client$ are terms of a language endowed with the parallel
%   composition~$ -\Par - $, then the semantics of~$- \llceil -$ is the
%   same one of~$ - \Par -$, but with the server and the client being
% distinguished, in order to prevent $\goodSym$ terms to ``commute'' from
% the server process into the client process.
%% \footnote{
%% In the implementation the reduction semantics is adapted in the
%% obvious way, %(\coqMT{lts_sys_s}).
%% and we use a location \texttt{c} for the client a location \texttt{s}
%% for the server, and systems are coded as \lstinline!s[p] || c[r]!.
%% These locations prevent server code from migrating into the client side,
%% and vice-versa.
%% }
%%%%%%%%%%%%%%%%%%%%%%%%%%
%
In general, every system~$\csys{\server~}{~\client}$ is the root of a
{\em state transition system} (STS), $\sts{ \SysStates }{ \st{ }} $,
where~$\SysStates$ is the set of states and~$\st{}$ is the reduction
relation.  For the sake of simplicity\footnote{In general the
  reduction semantics and the LTS of a calculus are defined
  independently, and connected via the Harmony lemma
  (\cite{sangiorgi}, Lemma 1.4.15 page 51).  %While this is out of
  %scope,
  We have a mechanised proof of it.}%
  %the equivalence~$\simeq$ used in our typeclass
  %\lstinline!LtsEq! enjoys the main property behind the proof of the
%Harmony lemma.}
  we derive the reduction relation from the LTS
semantics of servers and clients as specified by the rules in
\rfig{rules-STS}.
  %\ila{which is derived from the LTS
%  semantics of servers and clients as specified by the rules in
  %  Figure~\ref{fig:rules-STS}.}
In our mechanisation (\rfig{sketch-mechanisation-sts}), \lstinline!sts_step! is the
characteristic function of the reduction relation~$\st{}$, and
\lstinline!sts_stable! is the function that states whether a state can
reduce or not. Both functions are assumed decidable.
%
%\ilacom{I would put a definition environment for the following
%  definition, as for Definition~\ref{def:inf-transition-sequence}}\\

\begin{definition}[Computation]
  Given an STS $\sts{ \SysStates }{ \st{} }$ and a state
  $\sysstate_0 \in \SysStates$, a %\emph{reduction sequence} or
  \emph{computation} of $\sysstate_0$ is a finite or infinite
  reduction sequence\footnote{Which is defined as a coinductive
    type in our Coq development.}, \ie a partial function $\eta$ from
  $\N$ to $\SysStates$ whose domain is downward-closed, such that
  $\sysstate_0 = \eta(0)$
%\ilacom{something is missing here: we should say before that $\eta$ is
%  a partial function from $\N$ to $\SysStates$ whose domain is
%  downward-closed}
and %such that,
for each
$n \in \dom\eta \setminus \{0\}$, $\eta(n-1) \st{ } \eta(n)$.\hfill$\blacksquare$
\end{definition}

A computation~$\eta$ is
{\em infinite} if $ \mathit{dom}(\eta) = \N$. A computation~$\eta$ is
{\em maximal} if
% either there exists
% $ n \in \N \wehavethat \eta(n) \Nst{}$, or it is infinite.
either it is infinite or it cannot be extended,
%  \ie there exists
%  $ n \in \N \wehavethat \eta(n) \Nst{}$.
% \ilacom{Note that if this $n$ exists, it will necessarily
%   be $n = max( \mathit{dom}(\eta))$.}
\ie $\eta(n_{max}) \Nst{}$ where $n_{max} = max( \mathit{dom}(\eta))$.
To formally define the \mustpreorder, we assume a decidable
predicate~$\goodSym$ over clients.
A computation~$\eta$ of $\sysstate_0 =
\csys{\server_0}{\client_0}$
%\ilacom{I wrote it explicitly to remind the reader that $\sysstate_0$
%is a pair}
is {\em successful} if there exists $ n \in \N $ such that
$\good{ \mathsf{snd}(\eta(n)) }$.  We assume the predicate $\goodSym$
to be preserved by output actions.  To the best of our knowledge, this
assumption is true in all the papers on testing theory for
asynchronous calculi that rely on ad-hoc actions such as $\omega$ or
$\checkmark$ to signal success.  In \rapp{accs} we show that this
assumption holds for the language~\ACCS extended with the
process~$\Unit$.
%This is consistent with the \outputcommutativity axiom.
%
Moreover, when considering an equivalence on programs $\simeq$ that is
compatible with transitions, in the sense of Figure~\ref{fig:Axiom-LtsEq}, we
assume the predicate $\goodSym$ to be preserved also by this equivalence.
%
These assumptions are met by the frameworks in
  \cite{DBLP:conf/fsttcs/CastellaniH98,DBLP:journals/iandc/BorealeNP02,DBLP:journals/jlp/Hennessy05}.
  % but let us abstract away from details,
  %%%% NEW
  %%% \gb{Here we opt for a more general treatment based on LTSs, and use calculi only to streamline examples.}
  %%%%% OLD
  %
  %%% ILARIA: took off the following for CONCUR
  %
  % Here we abstract away from the calculi used in those papers, and we opt
  % for a more general treatment based on LTSs.
  %
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% \begin{definition}[\coqTS{iexec_from}]
%%   \label{def:inf-transition-sequence}
%%   Given a state $\state_0 \in \Proc$, %we say that
%%   an {\em infinite transition sequence} of $\state_0$ is a {\em total}
%%   function $ \eta : \N \longrightarrow \Proc \times \Acttau$ such that
%%    for every
%%     $n \in N \wehavethat \eta(n) = (\state_n,\alpha_n)$ and $\state_n \stx{\alpha_n} \state_{n+1}$.
%%    If a finite trace $\trace$ or an infinite transition sequence $\eta$
%%    contain only $\tau$ actions, it is called a {\em computation}.~\hfill$\blacksquare$
%% \end{definition}




%We follow \cite{DBLP:conf/lics/BredeH21} and define infinite sequences
%of processes as functions $\N \longrightarrow \Proc$.
%A {\em computation} $\eta$ is a sequence of processes $\seq{p_0,p_1,\ldots}$
%such that for every $n \in \N \wehavethat p_n \st{\tau} p_{n+1}$.
%We range over computations with $\eta$.

%% \ilacom{In the next couple of sentences, you use $\eta_{n}$ instead of
%%   $\eta(n)$.  I'm not sure it's a good idea, because one might want to
%%   use $\eta_1$ and $\eta_2$ to denote two different computations from
%%   a given state $\state_0$.}\\





%% , and for system use a parallel
%% operation $\Par$ that distinguishes the identities of the client and
%% the server, so that a $\Unit$ in a server~$\server$ does not mean that
%% the state $\csys{ \server }{ \client }$ is succesful.

\begin{definition}[Client satisfaction]%\coqME{must_ext}
  \label{def:must-extensional}
  We write $\Must{\server}{\client} $ if every maximal
  computation of $\csys{\server}{\client}$ is successful.\hfill$\blacksquare$
\end{definition}

%%% NO LONGER USEFUL
%% \noindent
%% We write $\NMust{\server}{\client}$ to mean $\lnot
%% (\Must{\server}{\client}) $. The prefix notation for $\opMust$ is unusual,
%% and we adopt it for it simplifies the presentation of our results, in
%% particular the statement of \req{musti-preserved-by-nf}.


\begin{definition}[\mustpreorder]% \coqMT{ctx_srv}, ]
  \label{def:testleq}
  \label{def:testleqS}
We let $ \server \testleqS \serverB$ whenever for every
client $r$ we have that
$\Must{\server}{\client}$ implies $\Must{\serverB}{\client}$.\hfill$\blacksquare$
\end{definition}

%% \noindent
%% \gb{The predicate $\opMust$ is a
%%   natural way to model liveness properties, and~$\testleqS$ is the
%% obvious contextual equivalence to preserve such properties, while
%% allowing code refactoring that is not observable by clients.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% @@@

\begin{example}
\label{ex:max-comp}
 Consider the system~$\csys{ \server_0 }{ \client_0 }$, where~$\server_0$
  and~$\client_0$ are the server and client given in
  \rfig{first-example}. The unique maximal computation of this system is
  $\csys{ \server_0 }{ \client_0 } \st{} \csys{ \server_1 }{ \client_1
  } \st{} \csys{ \server_3 }{ \client_3 }$.
This computation is successful since it leads the client to the $\goodSym$ state
$\client_3$.
% which is  $\goodSym$.
Hence, client  $\client_0$ is
satisfied by server $\server_0$.
%
%Note that,
Since \outputcommutativity implies a lack of causality
between the output $\co{{\tt str}}$ and the input ${\tt int}$ in the
client, it is the order between the input ${\tt str}$ and the output
$\co{\tt int}$ in the server that guides the order of client-server
interactions.\hfill$\qed$
\end{example}

\input{axioms-comments}



{\bfseries Calculi.}
%% Given a calculus of interest, together with the inference rules to
%% which give its LTS, one would like to show that said LTS satisfies the
%% axioms in \rfig{axioms}. For example,
%% \cite{DBLP:conf/concur/Selinger97} does so for the LTS of asynchronous \ACCS modulo bisimulation.
A number of asynchronous calculi
\cite{DBLP:conf/ecoop/HondaT91,boudol:inria-00076939,DBLP:conf/fsttcs/CastellaniH98,DBLP:journals/toplas/HennessyR02,palamidessi_2003,DBLP:conf/birthday/Sangiorgi19}
have an LTS that enjoys the axioms in \rfig{axioms}, at least up to
some structural equivalence $\equiv$. The reason is that these calculi
syntactically enforce outputs to have no continuation, \ie outputs can
only be composed in parallel with other
processes.\footnote{In the calculus \TACCS
    of~\cite{DBLP:conf/fsttcs/CastellaniH98} there is a construct of
    asynchronous output prefix, but its behaviour is to spawn the
    corresponding atom in parallel with the continuation, so it
      does not act as a prefix}.  For
example, Selinger~\cite{DBLP:conf/concur/Selinger97} shows that the
  axioms of \rfig{axioms} hold for the LTS of the calculus~\ACCS (the
asynchronous variant of CCS\footnote{The syntax of~\ACCS, which
    is closely inspired by that of the asynchronous $\pi$-calculus
    with input- and $\tau$-guarded choice~\cite{ACS96,ACS98}, is given
    in~\req{syntax-processes} and discussed later.})  modulo
bisimulation, and in
\rlem{ACCSmodulos-equiv-is-out-buffered-with-feedback} we prove this
for the LTS {of \ACCS modulo $\equiv$:%\lts{\modulo{\ACCS}{\equiv}}{L}{\modulo{\st{}}{\equiv}}:
\begin{lemma}
  \label{lem:ACCS-obaFB}
  We have that $\lts{\modulo{\ACCS}{\equiv}}{L}{\modulo{\st{}}{\equiv}} \in \obaFB$.
\end{lemma}
}
%%% GB:CLAIM olé olé TO BE HIDDEN. REQUIRES MUCH MORE WORK. 
%% We claim that also the early style LTS of the asynchronous
%% $\pi$-calculus enjoys the axioms of \rfig{axioms}.
To streamline
reasoning modulo some (structural) equivalence we introduce the
typeclass \lstinline|LstEq|, % to the hierarchy of
% typeclasses.
whose
instances are LTSs
% in which an equivalence~$\simeq$ exists,
equipped with an equivalence~$\simeq$
that satisfies the property in \rfig{Axiom-LtsEq}.
% \footnote{For
% instance, to reason on the LTS of \ACCS terms modulo the
% standard structural equivalence~$\equiv$, in our mechanisation it
% suffices to use the LTS \lts{\ACCS}{L}{\st{}\cdot\equiv}. \leo{I don't
%   get it} \ilacom{I don't understand it either.  I would omit this
%   footnote altogether.}}
Defining output-buffered agents with feedback using \lstinline!LtsEq!
does not entail any loss of generality, because the equivalence~$\simeq$
can be instantiated using the identity over the states~$\States$.
Further details can be found in \rapp{structural-congruence}.




%% \begin{figure}[t]
%% \hrulefill
%% $$
%% \begin{array}{lcl}
%%   p,q,r             & ::= &
%% \out{a}
%% \BNFsep g
%% \BNFsep p \Par p
%%  \BNFsep \rec{p}
%%  \BNFsep x
%% \\[.5em]
%%  g             & ::= &
%%  \Nil
%%  \BNFsep a.p
%%  \BNFsep \tau.p
%%  \BNFsep g \extc g
%% \end{array}
%% $$
%% \vspace{-1em}
%% \caption{Syntax of (core)~\ACCS.}% (\protect{\coqSyn{proc}}).
%% %where $\mu \in \Names, \mu_{\tau} \in \Names_{\tau}$.
%% %\caption{A minimal syntax for processes.% (\protect{\coqSyn{proc}}).
%% \hrulefill
%% \label{fig:syntax-processes}
%% \end{figure}



When convenient we denote LTSs using the following minimal syntax for \ACCS:
%which we give in \rfig{syntax-processes},
\begin{equation}
  \label{eq:syntax-processes}
    p,q,r ::= 
\out{\aa}
\BNFsep g
\BNFsep p \Par p
 \BNFsep \rec{p}
 \BNFsep x,
\qquad
 g ::= 
 \Nil
 \BNFsep a.p
 \BNFsep \tau.p
 \BNFsep g \extc g
%% \begin{array}{l@{\hskip 2pt}c@{\hskip 2pt}l@{\hskip 20pt}l@{\hskip 2pt}c@{\hskip 2pt}l}
%%   p,q,r & ::= &
%% \out{\aa}
%% \BNFsep g
%% \BNFsep p \Par p
%%  \BNFsep \rec{p}
%%  \BNFsep x,
%% &
%%  g & ::= &
%%  \Nil
%%  \BNFsep a.p
%%  \BNFsep \tau.p
%%  \BNFsep g \extc g
%% \end{array}
\end{equation}

as well as its standard LTS\footnote{Where the recursion rule is replaced by the one
    usually adopted for testing semantics, which introduces a
    $\tau$-transition before each unfolding.}  whose properties we
discuss in detail in \rapp{accs}.  This is exactly the syntax used
in~\cite{DBLP:conf/concur/Selinger97,DBLP:journals/iandc/BorealeNP02},
%\ilacom{I put only the references to
%  ~\cite{DBLP:conf/concur/Selinger97}
%  and~\cite{DBLP:journals/iandc/BorealeNP02} here, taking off the
%  reference to~\cite{sangiorgi} that was not appropriate to my view}
%the only difference being that we use
%recursive definitions instead of replication.
without the operators of restriction and relabelling.
Here the syntactic
category $g$ defines \emph{guards}, \ie the terms that may be used as
arguments for the $+$ operator.  Note that, apart from $\Nil$, only
input-prefixed and $\tau$-prefixed terms are allowed as guards, and
that the output prefix operator is replaced by \emph{atoms} $\out{a}$.
%% For instance we will use \ACCS in \rexa{pierre}.
% \ilacom{I think I said this already: in the syntax of \ACCS given
%   in~\rfig{syntax-processes}, the recursive construct, namely the two
%   productions $\rec{p}$ and $x$, should be in the syntactic category
%   of processes and not in that of guards. Otherwise one can write
%   terms such as $g = \rec{\out{a}} + \send{a}.p$, or even worse, terms
%   like $g' = (\rec{\out{a}}\Par \rec{\out{b}}) \,+\, \send{a}.p$, which
%   clearly we do not want to have. See for instance the paper on
%   asynchronous bisimulation [5] page 293, or Sangiorgi's book page
%   191, where the syntactic category $g$ is denoted $M$, and
%   corresponds to input and $\tau$ guarded sums, while the construct
%   for recursive processes, which is replication there, belongs to the
%   syntactic category of processes.}
In fact, this syntax is
completely justified by Selinger axioms, which, as we argued above,
specify that outputs cannot cause any other action, nor be in
conflict with it.

%%% LONG VERSION
%%% Indeed, \ACCS
%the core language in \rfig{syntax-processes}
%%%can be viewed as a syntax for Selinger LTSs.






\begin{figure}
  \hrulefill
%  \scalebox{.8}{%
  \begin{center}
    \begin{tikzcd}
      p
      \arrow[d, dash, dotted, "{\simeq}" description]
      &
      \phantom{p'}
      \\
      q
      \arrow[r, "\alpha"]
      &
      q'
    \end{tikzcd}
    $\Rightarrow$
    \begin{tikzcd}
      p
      \arrow[r, "\alpha"]
      \arrow[d, dash, dotted, "{\simeq}" description]
      &
      p' \arrow[d, dash, dotted, "{\simeq}" description]
      \\
      q \arrow[r, "\alpha"]
      &
      q'
    \end{tikzcd}
  \end{center}
    \vspace{-1em}
 % }
  \caption{Axiom stating that equivalence $\simeq$ is compatible with
    a transition relation.}
\label{fig:Axiom-LtsEq}
\hrulefill
\end{figure}









%% \begin{figure}[t]
%%   \hrulefill
%% %\begin{center}
%%   \centering%
%%   \scalebox{.8}{%
%%     \begin{tikzpicture}
%%       \node[state] (p) {$b.(\tau.\Omega + c.\co{d})$};
%%       \node[state][right =of p](p3){$\tau.\Omega + c.\co{d}$};
%%       \node[state][below right=+15pt and +20pt of p3](p2){$\Omega$};
%%       \node[state][above right=+15pt and +20pt of p3](p1){$\mailbox{\co{d}}$};
%%       \node[state][right =of p1](p4){$\Nil$};
%%       %Edges
%%       \path (p) edge[to] node[action,swap] {$b$} (p3)
%%       (p3) edge[to] node[action,above] {$\tau$} (p2)
%%       (p3) edge[to] node[action] {$c$} (p1)
%%       (p1) edge[to] node[action,swap] {$\co{d}$} (p4)
%%       (p2) edge [out=45, in=-45, loop] node[right] {$\tau$} (p2);
%%     \end{tikzpicture}
%%   }
%% %\end{center}
%%   \vspace{-2.5em}
%%   \caption{The LTS of \pierre, which is
%%     described in  \rexa{pierre}.}
%%      \label{fig:running-example}
%% \hrulefill
%% \end{figure}





%%%%%%%%%%%% VERTICAL PIERRE
%% \begin{figure}[t]
%% \hrulefill
%% \begin{center}
%%   \scalebox{.7}{%
%% \begin{tikzpicture}
%%   \node[state] (p) {$b.(\Omega + c.\co{d})$};
%%   \node[state][below =of p](p3){$\Omega + c.\co{d}$};
%%   \node[state][below left=of p3](p2){$\Omega$};
%%   \node[state][below right =of p3](p1){$\mailbox{\co{d}}$};
%%   \node[state][below =of p1](p4){$\Nil$};

%% %Edges
%% \path (p) edge[to] node[action,swap] {$b$} (p3)
%%       (p3) edge[to] node[action,above] {$\tau$} (p2)
%%       (p3) edge[to] node[action] {$c$} (p1)
%% (p1) edge[to] node[action,swap] {$\co{d}$} (p4)
%% (p2) edge  [out=225, in=-45, loop] node[below] {$\tau$} (p2);
%% \end{tikzpicture}
%% }
%% \end{center}
%%   \caption{The LTS of \pierre, which is described in  \rexa{pierre} and used in \rapp{counterexample}.}
%%   \label{fig:running-example}
%% \hrulefill
%% \end{figure}

%% \ilacom{Below, I fixed the definition of transition sequence in the
%%  same way as we fixed the definition of computation for systems.}

 \begin{definition}%[\coqTS{iexec_from}]
   \label{def:inf-transition-sequence}
   Given an LTS  $\lts{ \States }{ L }{ \st{} }$ and state $\state_0 \in
  \States$, a \emph{transition sequence} of $\state_0$ is a finite or infinite
  sequence of the form $\state_0 \alpha_1 \state_1 \alpha_2
  \state_2 \cdots$ with $\state_i \in \States$ and $\alpha_i \in L$, and
  such that, for every $n \geq 1$ such that $p_n$ is in the sequence we have
  $\state_{n-1} \stx{\alpha_n} \state_{n}$.
  %% Given an LTS  $\lts{ \States }{ L }{ \st{} }$ and state $\state_0 \in
  %% \States$, a \emph{transition sequence} of $\state_0$ is a finite or infinite
  %% sequence $\eta$ which is of the form $\state_0 \alpha_1 \state_1 \alpha_2
  %% \state_2 \cdots$ with that $\state_i \in \States$ and $\alpha_i \in L$, and
  %% such that, for every $n \in \mathit{dom}(\eta) \wehavethat \state_{n-1}
  %% \stx{\alpha_n} \state_{n}$.
~\hfill$\blacksquare$
 \end{definition}
 \noindent
 If a transition sequence %$\eta$
 is made only of  $\tau$-transitions,
 it is called a {\em computation}, the idea being that
 usually $\tau$-steps should be related to reductions via the Harmony
 lemma.

  % \ilacom{I moved here the definition of (maximal)
  %   computation for programs, because we use
  %   it in the proof that $\pierre \testleqS \Nil$.}


% We now discuss a behaviour and an inequality that prove that
% the alternative preorder of \cite{DBLP:conf/fsttcs/CastellaniH98}
% is not complete. Further details are in \rapp{counterexample}.

We give now an example that illustrates the use of the testing
machinery in our asynchronous setting. This is also a counter-example
to the completeness of the alternative preorder
proposed in~\cite{DBLP:conf/fsttcs/CastellaniH98}, as discussed
in detail in~\rapp{counterexample}.


%% \ilacom{IMPORTANT: we cannot write Pierre as we do in
%%   Example~\ref{ex:pierre}, because the~\ACCS syntax does not allow
%%   recursion to be used as a summand. Thus we should rewrite Pierre by adding an
%% action $\tau$ before $\Omega$, namely $\pierre = \ab.(\ila{\tau.}
%% \Omega \extc c.\co{d})$. Do you agree?
%% This should not change the essence of our results, but we should check
%% that we don’t use $\Omega + \ldots$ in other places too.}




\begin{example}
\label{ex:pierre}
%We would like the reader to get acquainted with \gb{the following
%process},%{\em \pierre}:
%% Let $\Omega = \rec{\tau. x}$.
%% The process $\pierre = \ab.(\tau.\Omega \extc c.\co{d}) $,
%% shown in \rfig{running-example},
Let $\Omega = \rec{\tau. x}$ and $\pierre = \ab.(\tau.\Omega \extc c.\co{d}) $.
%\pierre LTS is as follows:
The LTS of \pierre is as follows:
\begin{center}
  \scalebox{.9}{%
    \begin{tikzpicture}
      \node[state] (p) {$b.(\tau.\Omega + c.\co{d})$};
      \node[state][right =of p](p3){$\tau.\Omega + c.\co{d}$};
      \node[state][below right=+8pt and +20pt of p3](p2){$\Omega$};
      \node[state][above right=+8pt and +20pt of p3](p1){$\mailbox{\co{d}}$};
      \node[state][right =of p1](p4){$\Nil$};
      %Edges
      \path (p) edge[to] node[action,swap] {$b$} (p3)
      (p3) edge[to] node[action,below] {$\tau$} (p2)
      (p3) edge[to] node[action] {$c$} (p1)
      (p1) edge[to] node[action,swap] {$\co{d}$} (p4)
      (p2) edge [out=30, in=-30, loop] node[right] {$\tau$} (p2);
    \end{tikzpicture}
    }
  \end{center}
\pierre\ models a 
citizen confronted with an unpopular pension reform. To begin with, \pierre\ can only do
the input~$\ab$, which models % a reaction to
his getting aware of the brute-force imposition of the
reform by the government.
% , without a parliamentary vote.
After performing the input, \pierre reaches the state
$ \tau.\Omega \extc c.\co{d} $, where he behaves in a \nondeterministic
manner. He can internally choose not to trust the government for
  any positive change, in which case he will diverge, refusing any
  further interaction.  But this need not happen: in case the
  % environment (which here stands for the government)
   government offers
  the action $\co{c}$, which models a positive change in political
  decision, \pierre can decide to accept this change, and then
  he expresses his agreement with the output $\co{d}$,
  %outputting the atom $\co{d}$,
  which stands for ``done''.
 \hfill$\qed$
\end{example}



\begin{example}
  \label{ex:p-testleqS-Nil}
  We prove now the inequality $\pierre \testleqS \Nil$ by leveraging %
%%   \begin{equation}
%% \tag{$\star$}
%% \label{eq:running-example-1}
%% \end{equation}
%\ilacom{I have slightly rewritten the proof to make it more compact.}
%%%%%%%%%% New proof (Ilaria 20/1/24) %%%%%%%%%%%%%%%%%%%
    %We leverage
    the possibility of divergence of~$\pierre$
after the input~$\ab$.
  % First we prove that $ \Must{\pierre}{\client}$ and $\client \st{ \co{b}}$ imply $ \good{\client} $.
Fix an~$\client$ such that $ \Must{\pierre}{\client} $. We
distinguish two cases, according to whether $\client \st{ \co{b}}$
or $\client \not \st{ \co{b}}$.


$i)$ %
Let $\client \st{ \co{b}} \client'$ for some~$\client'$.
Consider the maximal computation
$ \csys{ \pierre }{\client} \st{} \csys{\tau.\Omega \extc
  c.\co{d}}{\client'} \st{} \csys{\Omega}{\client'} \st{}
\ldots $ in which~$\pierre$ diverges and $\client$ does not move after
the first output.  Since $\Must{\pierre}{\client}$,
either~$\good{\client}$ or $\good{\client'}$. In
case~$\good{\client'}$, by~\rlem{output-shape} we get also
$\good{\client}$. Hence $ \Must{\Nil}{\client}$.

$ ii)$ Let $\client \Nst{\co{b}}$.
Suppose $\client = \client_0 \st{\tau} \client_1
  \st{\tau} \client_2 \st{\tau} \ldots$ is a maximal computation of
  ~$\client$.
  Then %the system
  $\csys{ \pierre }{\client}$ has a maximal computation $
\csys{\pierre}{\client_0} \st{}
\csys{\pierre}{\client_1} \st{}
\csys{\pierre}{\client_2} \st{}\ldots$.
As $\Must{\pierre}{\client}$,
there must exist an $i \in \N$ such that $\good{\client_i}$. Hence
$ \Must{\Nil}{\client}$.
\hfill$\qed$
%%%%%%%%%%%% End of new proof %%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%%%%%%%%%%%% Previous proof %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% We leverage the divergence of~$\pierre$ after the \ila{input}~$b$.
%   First we prove that $ \Must{\pierre}{\client}$ and $\client \st{ \co{b}}$ imply $ \good{\client} $.
%    Fix an~$\client$ such that $ \Must{\pierre}{\client} $ and $\client \st{ \co{b}} \client'$ for some~$\client'$.
%    Consider the maximal computation
%    $
%    \csys{ \pierre }{\client} \st{\tau}
%    \csys{\Omega \extc c.\co{d}}{\client'} \st{\tau}
%    \csys{\Omega \extc c.\co{d}}{\client'} \st{\tau}
%    \ldots
%    $
%    in which the process~$\Omega \extc c.\co{d}$ diverges.
%   Since $\Must{\pierre}{\client}$ either~$\good{\client}$ or $\good{\client'}$.
%   Note that if~$\good{\client'}$ then thanks to \rlem{output-shape} we obtain $\good{\client}$.

%   Now we prove that  $\Must{\pierre}{\client}$ and $\client \Nst{\co{b}}$ imply $\good{\client}$.
%   Pick a suitable $\client$, and fix a sequence of reductions done
%   by~$\client$, \ie  $\client = \client_0 \st{\tau} \client_1 \st{\tau} \client_2 \st{\tau} \ldots$.
%   By zipping it with $ \pierre $ we obtain a maximal computation
%   in which $ \pierre $ never changes and $\client$ possibly diverges.
%   As $\Must{\pierre}{\client}$ one of the
%   states reached by $\client$ must be successful.
%   This proves that if~$\client \Nst{ \co{b}}$ then
%   $\client$ converges to success, that is for every sequence
%   $ \client = \client_0 \st{\tau} \client_1 \st{\tau} \client_2 \st{\tau} \client_3 \ldots $
%   there exists an $i \in \N$ such that $\good{\client_i}$.

%   Fix an~$\client$ such that $\Must{\pierre}{\client}$.
%   If $\client \st{ \co{b}}$ then $\good{\client}$ and so $\Must{\Nil}{\client}$.
%   If $\client \Nst{ \co{b} }$ then we have that
%   $\Must{\Nil}{\client}$ because~$\client$ converges to success, and
%   this concludes the argument.\hfill$\qed$
%%%%%%%%%% End of previous proof %%%%%%%%%%%%%%%%%%%%%%%%
\end{example}
%We will use \req{running-example-1} to discuss details about our
%completeness result, and to explain the problem in the one by \cite{DBLP:conf/fsttcs/CastellaniH98}.
%We managed to prove \req{running-example-1}

%%% THIS IS A NON-SEQUITUR, BECAUSE WE DO NOT REALLY PROVE MUCH VIA
%%% THE ALTERNATIVE CHARACTERISATIONS.
The argument in \rexa{p-testleqS-Nil} can directly use \rdef{testleq}
because it is very simple to reason on the process $\Nil$.
The issues brought about by the contextuality of \rdef{testleq},
though, hinder showing general properties of~$\testleqS$.
Even proving the following seemingly obvious fact is already cumbersome:
  \begin{equation}
    \label{eq:mailbox-hoisting}
     \tau.(\co{\aa} \Par \co{b}) \extc
     \tau.(\co{\aa} \Par \co{c}) \testleqS \co{\aa} \Par (\tau.\co{b} \extc
     \tau.\co{c})
  \end{equation}
This motivates the study of alternative characterisations for~$\testleqS$,
and in the rest of the paper we present two preorders that fit the purpose,
and let us establish \req{mailbox-hoisting}.
%We will use one of them to 


%\gb{Give references to the definitions in appendix H. Everybody OK ?}
We conclude this section by recalling auxiliary and rather standard
notions: given an LTS $\lts{\States}{L}{\st{}}$,
the weak transition relation $\state \wt{ \trace } \stateA $,
where $ \trace \in\Actfin$,
is defined via the rules
\begin{description}
\item[\rname{wt-refl}]
  $\state \wt{\varepsilon} \state$
\item[\rname{wt-tau}]
  $\state \wt{ \trace } \stateB$ if $\state\st{\tau}\stateA$
  and $\stateA \wt{ \trace } \stateB$
\item[\rname{wt-mu}]
  $\state \wt{\mu.s} \stateB$ if $\state \st{\mu} \stateA$
  and $\stateA \wt{\trace} \stateB$
\end{description}
We write $ \state \wt{ \trace }  $ to mean  $\exists \stateA \suchthat \state
                                     \wt{ \trace } \stateA$, where $\trace \in
                                     \Actfin$.

%% WHERE IS THIS USED  IN THE RUNNING TEXT ?
%% We let $\str{ \I }$ % (\coqConv{str})
%% be defined as the set of all permutations of the elements of $\I$.
%% For instance $ \str{
%%   \mset{ a, a, b }}  = \set{ a.a.b, a.b.a, b.a.a }$.
%Plainly, $ p \wt{ \emptyMset } q$ if and only if $ p \wt{ \varepsilon } q$.

%{\bfseries Convergence along traces}

\renewcommand{\stateA}{p'}
%Given an LTS in which $\tau$ transitions represent computation steps,
%Given an LTS $\lts{\States}{L}{\st{}}$,
We write $\state \conv$ and say that {\em $\state$ converges} if every
computation of~$\state$ is finite, and we lift the convergence predicate
to finite traces by letting the relation
${\cnvalong} \subseteq \States \times \Actfin$ be the least one that
satisfies the following rules% (\coqConv{cnv}),
\begin{description}
\item[\cnvepsilon] $\state \cnvalong \varepsilon$ if $\state \conv$,
\item[\cnvmu] $ \state \cnvalong \mu.\trace $ if $p \conv$ and
  $\state \wt{\mu} \stateA \implies \stateA \cnvalong \trace$.
\end{description}



\leaveout{
\begin{table}
  \hrulefill
\begin{center}
\begin{tabular}{lcl}
%$ \state \st{ \alpha }$ & means & $\exists \stateA \suchthat \state \st{\alpha} \stateA$,\\
$ \state_0 \stx{ \alpha_0 \ldots \alpha_{n-1} } \state_n$ & means & $ \exists \state_1\ldots \state_n \suchthat \state_0 \st{ \alpha_0 } \state_1  \cdots \st{ \alpha_{n-1} } \state_n$, \\
   $ \state \stx{ \trace } $ & means &
  $\exists
                                                            \stateA \suchthat
                                                            \state \stx{ \trace }
                                     \stateA$,  where $\trace \in \Acttau^+$,
  \\
% $ \state \wt{ \trace }  $ & means & $\exists \stateA \suchthat \state
%                                     \wt{ \trace } \stateA$, where $\trace \in
%                                    \Actfin$,
%\\
  %% $ \state \wt{ X } \stateA $ & means & $\exists \trace \in X \suchthat \state \wt{ \trace } \stateA
  %% $, where $X \subseteq \Actfin$,
  %% \\
  %% $\state \wt{\I} \stateA$ & means & $\exists \trace \in \str{\I} \suchthat \state \wt{ \trace } \stateA$,
  %% \\
  %% $ \state \wt{\I} $ & means & $\exists \stateA. \state
  %% \wt{\I} \stateA$%,
  %% \\[5pt]
  %%  $X \conv$ & means &  $\forall \state \in X \suchthat\state
  %% \conv$,
  %% \\[5pt]
  %% $ X \cnvalong \trace $ & means & $\forall \state \in X
  %% \suchthat \state \cnvalong \trace $
\end{tabular}
\end{center}
\bigskip
\caption{Notational conventions}
\hrulefill
\label{tab:notation}
\end{table}
}


%% \pl{
%% Traces of output actions have no impact on the stability of processes.
%% %% on their input actions.%, and on their being (not) $\goodSym$. %%
%% \begin{lemma}
%%   \label{lem:st-wtout-st}  %% \label{lem:st-wtout-inp} %%
%%   For all $\server, \server' \in \States$ and trace $\trace \in \co{\Names}^\star$ such that
%%   $\server \stable$ and $\server \wt{ \trace } \server'$
%%   %% \begin{enumerate} %%
%%   then %(\coqLTS{st_wtout_st})
%%   $\server' \stable$,
%%   %% \item %(\coqLTS{st_wtout_inp})                                                     %%
%%   %%   for every $\aa \in \Names$,                                                      %%
%%   %%   $\server \stable$, $\server \st{\aa}$ and $\server \wt{ \trace } \server'$ imply %%
%%   %%   $\server' \st{\aa}$.                                                             %%
%%   and %(\coqLTS{st_wtout_inp})
%%   for every $\aa \in \Names$, $\server \Nst{\aa}$ implies $\server' \Nst{\aa}$.
%%   %% \end{enumerate} %%
%% \end{lemma}
%% }

%% By assumption, outputs preserve the predicate~$\goodSym$. \ilacom{Put
%%   somewhere else?}



  To understand the next section, one should
  keep in mind that all the predicates defined
  above have an implicit parameter: the LTS of programs. % over which we predicate.
  By changing this parameter, we may change the meaning of the
  predicates.
  % \TODO{I do not understand why the processes $\tau.\Nil$ is used.
  % Should we not discuss just $\Omega$ ?}
  % For instance, letting $\Omega$ be the~\ACCS process
  %   $\rec{\tau. x}$, in the standard LTS
  % $\lts{\ACCS}{\st{}}{\Acttau}$ we have $ \tau.\Nil \st{ \tau } \Nil$
  % and $\lnot (\Omega \conv)$, while in the LTS $\lts{\ACCS}{ \emptyset
  % }{\Acttau}$ we have $\tau.\Nil \Nst{ \tau }$ and $\Omega \conv$.%
  % \footnote{\gb{$\Omega \Nst{\tau}$ and thus $\Omega
  %     \conv$}. \ilacom{In fact, this holds for any $p$ in the
  %     second LTS.}}
  For instance, letting~$\Omega$ be the~\ACCS process~$\rec{\tau. x}$, in the standard LTS
  $\lts{\ACCS}{\st{}}{\Acttau}$ we have~$ \Omega \st{ \tau } \Omega$
  and $\lnot (\Omega \conv)$, while in the LTS $\lts{\ACCS}{ \emptyset
  }{\Acttau}$ we have $\Omega \Nst{\tau}\,$ and thus $\Omega \conv$.
  %
  In other words, the {\em same} predicates can be applied to
  different LTSs, and since the alternative characterisations
  of~$\testleqS$ are defined using such predicates, they
  can relate different LTSs.
